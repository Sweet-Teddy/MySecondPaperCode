{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "pregnant-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from numpy import *\n",
    "from math import sqrt\n",
    "from pandas import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Bidirectional, Activation\n",
    "from tensorflow.keras.layers import BatchNormalization, Embedding, TimeDistributed, LeakyReLU\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics as ms\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from pickle import load\n",
    "from sklearn import metrics as ms\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, average_precision_score, f1_score, recall_score\n",
    "\n",
    "# X_train = np.load(\"./saveData/IBM/X_train.npy\", allow_pickle=True)\n",
    "# y_train = np.load(\"./saveData/IBM/y_train.npy\", allow_pickle=True)\n",
    "# X_test = np.load(\"./saveData/IBM/X_test.npy\", allow_pickle=True)\n",
    "# y_test = np.load(\"./saveData/IBM/y_test.npy\", allow_pickle=True)\n",
    "# X_val = np.load(\"./saveData/IBM/X_val.npy\", allow_pickle=True)\n",
    "# y_val = np.load(\"./saveData/IBM/y_val.npy\", allow_pickle=True)\n",
    "\n",
    "# X_train = np.load(\"./saveData/TSLA/X_train.npy\", allow_pickle=True)\n",
    "# y_train = np.load(\"./saveData/TSLA/y_train.npy\", allow_pickle=True)\n",
    "# X_test = np.load(\"./saveData/TSLA/X_test.npy\", allow_pickle=True)\n",
    "# y_test = np.load(\"./saveData/TSLA/y_test.npy\", allow_pickle=True)\n",
    "# X_val = np.load(\"./saveData/TSLA/X_val.npy\", allow_pickle=True)\n",
    "# y_val = np.load(\"./saveData/TSLA/y_val.npy\", allow_pickle=True)\n",
    "\n",
    "X_train = np.load(\"./saveData/S&P500/X_train.npy\", allow_pickle=True)\n",
    "y_train = np.load(\"./saveData/S&P500/y_train.npy\", allow_pickle=True)\n",
    "X_test = np.load(\"./saveData/S&P500/X_test.npy\", allow_pickle=True)\n",
    "y_test = np.load(\"./saveData/S&P500/y_test.npy\", allow_pickle=True)\n",
    "X_val = np.load(\"./saveData/S&P500/X_val.npy\", allow_pickle=True)\n",
    "y_val = np.load(\"./saveData/S&P500/y_val.npy\", allow_pickle=True)\n",
    "\n",
    "# X_train = np.load(\"./saveData/PAICC/X_train.npy\", allow_pickle=True)\n",
    "# y_train = np.load(\"./saveData/PAICC/y_train.npy\", allow_pickle=True)\n",
    "# X_test = np.load(\"./saveData/PAICC/X_test.npy\", allow_pickle=True)\n",
    "# y_test = np.load(\"./saveData/PAICC/y_test.npy\", allow_pickle=True)\n",
    "# X_val = np.load(\"./saveData/PAICC/X_val.npy\", allow_pickle=True)\n",
    "# y_val = np.load(\"./saveData/PAICC/y_val.npy\", allow_pickle=True)\n",
    "\n",
    "# X_train = np.load(\"./saveData/X_train.npy\", allow_pickle=True)\n",
    "# y_train = np.load(\"./saveData/y_train.npy\", allow_pickle=True)\n",
    "# X_test = np.load(\"./saveData/X_test.npy\", allow_pickle=True)\n",
    "# y_test = np.load(\"./saveData/y_test.npy\", allow_pickle=True)\n",
    "# X_val = np.load(\"./saveData/X_val.npy\", allow_pickle=True)\n",
    "# y_val = np.load(\"./saveData/y_val.npy\", allow_pickle=True)\n",
    "\n",
    "\n",
    "# X_train = np.load(\"./saveData/MSFT/X_train.npy\", allow_pickle=True)\n",
    "# y_train = np.load(\"./saveData/MSFT/y_train.npy\", allow_pickle=True)\n",
    "# X_test = np.load(\"./saveData/MSFT/X_test.npy\", allow_pickle=True)\n",
    "# y_test = np.load(\"./saveData/MSFT/y_test.npy\", allow_pickle=True)\n",
    "# X_val = np.load(\"./saveData/MSFT/X_val.npy\", allow_pickle=True)\n",
    "# y_val = np.load(\"./saveData/MSFT/y_val.npy\", allow_pickle=True)\n",
    "\n",
    "# X_train = np.load(\"./saveData/SSE/X_train.npy\", allow_pickle=True)\n",
    "# y_train = np.load(\"./saveData/SSE/y_train.npy\", allow_pickle=True)\n",
    "# X_test = np.load(\"./saveData/SSE/X_test.npy\", allow_pickle=True)\n",
    "# y_test = np.load(\"./saveData/SSE/y_test.npy\", allow_pickle=True)\n",
    "# X_val = np.load(\"./saveData/SSE/X_val.npy\", allow_pickle=True)\n",
    "# y_val = np.load(\"./saveData/SSE/y_val.npy\", allow_pickle=True)\n",
    "\n",
    "# X_train = np.load(\"./saveData/IBM/X_train.npy\", allow_pickle=True)\n",
    "# y_train = np.load(\"./saveData/IBM/y_train.npy\", allow_pickle=True)\n",
    "# X_test = np.load(\"./saveData/IBM/X_test.npy\", allow_pickle=True)\n",
    "# y_test = np.load(\"./saveData/IBM/y_test.npy\", allow_pickle=True)\n",
    "# X_val = np.load(\"./saveData/IBM/X_val.npy\", allow_pickle=True)\n",
    "# y_val = np.load(\"./saveData/IBM/y_val.npy\", allow_pickle=True)\n",
    "# yc_train = np.load(\"./saveData/yc_train.npy\", allow_pickle=True)\n",
    "# yc_test = np.load(\"./saveData/yc_test.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "graduate-grade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "driven-couple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'跌': 1672, '涨': 1893, '平': 296}\n"
     ]
    }
   ],
   "source": [
    "dict_count = {}\n",
    "dict_count['跌']=0\n",
    "dict_count['涨']=0\n",
    "dict_count['平']=0\n",
    "for i in range(len(y_train)):\n",
    "    if(y_train[i][0] ==1):\n",
    "        dict_count['跌'] += 1\n",
    "    if(y_train[i][1] == 1):\n",
    "        dict_count['平'] += 1\n",
    "    if(y_train[i][2] == 1):\n",
    "        dict_count['涨'] += 1\n",
    "print(dict_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "demonstrated-prison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'跌': 174, '涨': 174, '平': 25}\n"
     ]
    }
   ],
   "source": [
    "dict_count = {}\n",
    "dict_count['跌']=0\n",
    "dict_count['涨']=0\n",
    "dict_count['平']=0\n",
    "for i in range(len(y_val)):\n",
    "    if(y_val[i][0] ==1):\n",
    "        dict_count['跌'] += 1\n",
    "    if(y_val[i][1] == 1):\n",
    "        dict_count['平'] += 1\n",
    "    if(y_val[i][2] == 1):\n",
    "        dict_count['涨'] += 1\n",
    "print(dict_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "military-oriental",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'跌': 318, '涨': 373, '平': 56}\n"
     ]
    }
   ],
   "source": [
    "dict_count = {}\n",
    "dict_count['跌']=0\n",
    "dict_count['涨']=0\n",
    "dict_count['平']=0\n",
    "for i in range(len(y_test)):\n",
    "    if(y_test[i][0] ==1):\n",
    "        dict_count['跌'] += 1\n",
    "    if(y_test[i][1] == 1):\n",
    "        dict_count['平'] += 1\n",
    "    if(y_test[i][2] == 1):\n",
    "        dict_count['涨'] += 1\n",
    "print(dict_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-bathroom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "recreational-pension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'跌': 318, '涨': 373, '平': 56}"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "elegant-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "average-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train[0:5001]\n",
    "# y_train = y_train[0:5001]\n",
    "# X_test = X_test[0:5001]\n",
    "# y_test = y_test[0:5001]\n",
    "# X_val = X_val[0:5001]\n",
    "# y_val = y_val[0:5001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "threatened-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "min_delta_val = 0.0001\n",
    "lr_cb = ReduceLROnPlateau(monitor = 'val_loss',  \n",
    "                          factor = 0.2, min_delta = min_delta_val, patience = 10, verbose = 1)\n",
    "es_cb = EarlyStopping(monitor = 'accuracy', \n",
    "                      min_delta=min_delta_val, patience = 50, verbose = 1, restore_best_weights = True)\n",
    "\n",
    "callbacks_model = [lr_cb, es_cb]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "voluntary-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Parameters\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 60\n",
    "N_EPOCH = 1000\n",
    "dropout = 0.2\n",
    "input_dim = X_train.shape[1]\n",
    "feature_size = X_train.shape[2]\n",
    "#做3分类\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "#output_dim = 3\n",
    "\n",
    "# METRICS = [\n",
    "#       keras.metrics.TruePositives(name='tp'),\n",
    "#       keras.metrics.FalsePositives(name='fp'),\n",
    "#       keras.metrics.TrueNegatives(name='tn'),\n",
    "#       keras.metrics.FalseNegatives(name='fn'), \n",
    "#       keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "#       keras.metrics.Precision(name='precision'),\n",
    "#       keras.metrics.Recall(name='recall'),\n",
    "#       keras.metrics.AUC(name='auc'),\n",
    "#       keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "# ]\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def basic_lstm(input_dim, feature_size):\n",
    "    print(\"model dim: \", input_dim, output_dim)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=(input_dim,feature_size), batch_size=None))\n",
    "    #model.add(tf.keras.layers.GaussianNoise(stddev=0.2))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "    #model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr = LR),metrics=METRICS)\n",
    "#     model = Sequential()\n",
    "#     model.add(Bidirectional(LSTM(units= 128), input_shape=(input_dim, feature_size)))\n",
    "#     model.add(Dense(64))\n",
    "#     model.add(Dense(units=output_dim,activation='softmax'))\n",
    "#     model.compile(optimizer=Adam(lr = LR), loss='mse')\n",
    "    history = model.fit(X_train, y_train, epochs=N_EPOCH, batch_size=BATCH_SIZE, validation_data=(X_val, y_val),\n",
    "                        verbose=1, shuffle=False , callbacks=callbacks_model)\n",
    "    #, callbacks=callbacks_model\n",
    "\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='validation')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "    return model,history\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "cooperative-tourism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3861, 30, 12)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "endangered-awareness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3861, 3)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "unlike-pleasure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373, 30, 12)"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "engaged-listening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373, 3)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "wooden-scheme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "sharing-component",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.47399758, -0.48502877, -0.48611697, ..., -0.56631567,\n",
       "         -0.49333447, -0.47863195],\n",
       "        [-0.48375182, -0.48275766, -0.47929496, ..., -0.56356572,\n",
       "         -0.49228977, -0.47479727],\n",
       "        [-0.47482155, -0.48615095, -0.48540917, ..., -0.56437864,\n",
       "         -0.4911695 , -0.48750781],\n",
       "        ...,\n",
       "        [-0.45213244, -0.45748201, -0.44929919, ..., -0.55094688,\n",
       "         -0.5001247 , -0.45326336],\n",
       "        [-0.45487008, -0.4547657 , -0.44765342, ..., -0.5453208 ,\n",
       "         -0.50112965, -0.44546462],\n",
       "        [-0.44364514, -0.45152385, -0.43769022, ..., -0.53899112,\n",
       "         -0.50085974, -0.4433871 ]],\n",
       "\n",
       "       [[-0.48375182, -0.48275766, -0.47929496, ..., -0.56356572,\n",
       "         -0.49228977, -0.47479727],\n",
       "        [-0.47482155, -0.48615095, -0.48540917, ..., -0.56437864,\n",
       "         -0.4911695 , -0.48750781],\n",
       "        [-0.49571206, -0.50429277, -0.4996372 , ..., -0.56635666,\n",
       "         -0.49203321, -0.49713727],\n",
       "        ...,\n",
       "        [-0.45487008, -0.4547657 , -0.44765342, ..., -0.5453208 ,\n",
       "         -0.50112965, -0.44546462],\n",
       "        [-0.44364514, -0.45152385, -0.43769022, ..., -0.53899112,\n",
       "         -0.50085974, -0.4433871 ],\n",
       "        [-0.44442477, -0.45558499, -0.44623771, ..., -0.53740257,\n",
       "         -0.4976432 , -0.44777284]],\n",
       "\n",
       "       [[-0.47482155, -0.48615095, -0.48540917, ..., -0.56437864,\n",
       "         -0.4911695 , -0.48750781],\n",
       "        [-0.49571206, -0.50429277, -0.4996372 , ..., -0.56635666,\n",
       "         -0.49203321, -0.49713727],\n",
       "        [-0.50376526, -0.50868344, -0.4999027 , ..., -0.56915854,\n",
       "         -0.49148616, -0.49775459],\n",
       "        ...,\n",
       "        [-0.44364514, -0.45152385, -0.43769022, ..., -0.53899112,\n",
       "         -0.50085974, -0.4433871 ],\n",
       "        [-0.44442477, -0.45558499, -0.44623771, ..., -0.53740257,\n",
       "         -0.4976432 , -0.44777284],\n",
       "        [-0.4520085 , -0.44572594, -0.44436187, ..., -0.53101633,\n",
       "         -0.49603751, -0.43812315]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.10191899,  0.09844859,  0.10763956, ...,  0.02224073,\n",
       "          0.08439658,  0.10957388],\n",
       "        [ 0.10675621,  0.11012453,  0.11147095, ...,  0.02847544,\n",
       "          0.08446007,  0.11779266],\n",
       "        [ 0.11906198,  0.11698222,  0.12870742, ...,  0.03486239,\n",
       "          0.08424404,  0.12585961],\n",
       "        ...,\n",
       "        [ 0.14338109,  0.14406585,  0.15299598, ...,  0.06838837,\n",
       "          0.15770593,  0.15161822],\n",
       "        [ 0.15002566,  0.14644383,  0.14899653, ...,  0.06732029,\n",
       "          0.16193591,  0.15127789],\n",
       "        [ 0.14913085,  0.14770843,  0.15813689, ...,  0.06755595,\n",
       "          0.16544866,  0.15608243]],\n",
       "\n",
       "       [[ 0.10675621,  0.11012453,  0.11147095, ...,  0.02847544,\n",
       "          0.08446007,  0.11779266],\n",
       "        [ 0.11906198,  0.11698222,  0.12870742, ...,  0.03486239,\n",
       "          0.08424404,  0.12585961],\n",
       "        [ 0.12487371,  0.12242398,  0.13291037, ...,  0.04078108,\n",
       "          0.08486773,  0.12963429],\n",
       "        ...,\n",
       "        [ 0.15002566,  0.14644383,  0.14899653, ...,  0.06732029,\n",
       "          0.16193591,  0.15127789],\n",
       "        [ 0.14913085,  0.14770843,  0.15813689, ...,  0.06755595,\n",
       "          0.16544866,  0.15608243],\n",
       "        [ 0.15214308,  0.14580261,  0.14036943, ...,  0.06814279,\n",
       "          0.16624867,  0.1437723 ]],\n",
       "\n",
       "       [[ 0.11906198,  0.11698222,  0.12870742, ...,  0.03486239,\n",
       "          0.08424404,  0.12585961],\n",
       "        [ 0.12487371,  0.12242398,  0.13291037, ...,  0.04078108,\n",
       "          0.08486773,  0.12963429],\n",
       "        [ 0.12608745,  0.11824694,  0.13068058, ...,  0.04692005,\n",
       "          0.08498902,  0.13060777],\n",
       "        ...,\n",
       "        [ 0.14913085,  0.14770843,  0.15813689, ...,  0.06755595,\n",
       "          0.16544866,  0.15608243],\n",
       "        [ 0.15214308,  0.14580261,  0.14036943, ...,  0.06814279,\n",
       "          0.16624867,  0.1437723 ],\n",
       "        [ 0.13601008,  0.14411934,  0.14499707, ...,  0.06929998,\n",
       "          0.16692241,  0.1515932 ]]])"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-swing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-decision",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model dim:  30 3\n",
      "Epoch 1/1000\n",
      "65/65 [==============================] - 9s 145ms/step - loss: 0.9301 - tp: 1117.0000 - fp: 1189.0000 - tn: 6533.0000 - fn: 2744.0000 - accuracy: 0.4753 - precision: 0.4844 - recall: 0.2893 - auc: 0.7044 - prc: 0.4713 - val_loss: 1.0329 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 746.0000 - val_fn: 373.0000 - val_accuracy: 0.4477 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6781 - val_prc: 0.4445\n",
      "Epoch 2/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9221 - tp: 1112.0000 - fp: 1177.0000 - tn: 6545.0000 - fn: 2749.0000 - accuracy: 0.4887 - precision: 0.4858 - recall: 0.2880 - auc: 0.7031 - prc: 0.4681 - val_loss: 0.9044 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7027 - val_prc: 0.4615\n",
      "Epoch 3/1000\n",
      "65/65 [==============================] - 7s 109ms/step - loss: 0.9174 - tp: 1059.0000 - fp: 1104.0000 - tn: 6618.0000 - fn: 2802.0000 - accuracy: 0.4921 - precision: 0.4896 - recall: 0.2743 - auc: 0.7038 - prc: 0.4711 - val_loss: 0.9018 - val_tp: 166.0000 - val_fp: 191.0000 - val_tn: 555.0000 - val_fn: 207.0000 - val_accuracy: 0.4665 - val_precision: 0.4650 - val_recall: 0.4450 - val_auc: 0.7015 - val_prc: 0.4605\n",
      "Epoch 4/1000\n",
      "65/65 [==============================] - 8s 121ms/step - loss: 0.9157 - tp: 1057.0000 - fp: 1115.0000 - tn: 6607.0000 - fn: 2804.0000 - accuracy: 0.4792 - precision: 0.4866 - recall: 0.2738 - auc: 0.7016 - prc: 0.4714 - val_loss: 0.8999 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 746.0000 - val_fn: 373.0000 - val_accuracy: 0.4665 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6993 - val_prc: 0.4614\n",
      "Epoch 5/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9164 - tp: 894.0000 - fp: 986.0000 - tn: 6736.0000 - fn: 2967.0000 - accuracy: 0.4703 - precision: 0.4755 - recall: 0.2315 - auc: 0.6976 - prc: 0.4641 - val_loss: 0.8992 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 746.0000 - val_fn: 373.0000 - val_accuracy: 0.4665 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6928 - val_prc: 0.4512\n",
      "Epoch 6/1000\n",
      "65/65 [==============================] - 7s 108ms/step - loss: 0.9161 - tp: 804.0000 - fp: 859.0000 - tn: 6863.0000 - fn: 3057.0000 - accuracy: 0.4722 - precision: 0.4835 - recall: 0.2082 - auc: 0.6990 - prc: 0.4700 - val_loss: 0.9000 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 746.0000 - val_fn: 373.0000 - val_accuracy: 0.4665 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6971 - val_prc: 0.4601\n",
      "Epoch 7/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9126 - tp: 812.0000 - fp: 826.0000 - tn: 6896.0000 - fn: 3049.0000 - accuracy: 0.4838 - precision: 0.4957 - recall: 0.2103 - auc: 0.7049 - prc: 0.4755 - val_loss: 0.8996 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 746.0000 - val_fn: 373.0000 - val_accuracy: 0.4665 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6982 - val_prc: 0.4577\n",
      "Epoch 8/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9142 - tp: 788.0000 - fp: 817.0000 - tn: 6905.0000 - fn: 3073.0000 - accuracy: 0.4794 - precision: 0.4910 - recall: 0.2041 - auc: 0.7023 - prc: 0.4727 - val_loss: 0.9001 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 746.0000 - val_fn: 373.0000 - val_accuracy: 0.4665 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6996 - val_prc: 0.4615\n",
      "Epoch 9/1000\n",
      "65/65 [==============================] - 7s 108ms/step - loss: 0.9143 - tp: 763.0000 - fp: 780.0000 - tn: 6942.0000 - fn: 3098.0000 - accuracy: 0.4786 - precision: 0.4945 - recall: 0.1976 - auc: 0.7012 - prc: 0.4688 - val_loss: 0.9002 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 746.0000 - val_fn: 373.0000 - val_accuracy: 0.4665 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6934 - val_prc: 0.4542\n",
      "Epoch 10/1000\n",
      "65/65 [==============================] - 7s 101ms/step - loss: 0.9142 - tp: 742.0000 - fp: 815.0000 - tn: 6907.0000 - fn: 3119.0000 - accuracy: 0.4740 - precision: 0.4766 - recall: 0.1922 - auc: 0.7008 - prc: 0.4711 - val_loss: 0.9010 - val_tp: 109.0000 - val_fp: 132.0000 - val_tn: 614.0000 - val_fn: 264.0000 - val_accuracy: 0.4665 - val_precision: 0.4523 - val_recall: 0.2922 - val_auc: 0.6933 - val_prc: 0.4572\n",
      "Epoch 11/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9141 - tp: 715.0000 - fp: 752.0000 - tn: 6970.0000 - fn: 3146.0000 - accuracy: 0.4779 - precision: 0.4874 - recall: 0.1852 - auc: 0.7021 - prc: 0.4740 - val_loss: 0.9014 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.6953 - val_prc: 0.4569\n",
      "Epoch 12/1000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.9122 - tp: 742.0000 - fp: 772.0000 - tn: 6950.0000 - fn: 3119.0000 - accuracy: 0.4820 - precision: 0.4901 - recall: 0.1922 - auc: 0.7050 - prc: 0.4746 - val_loss: 0.9004 - val_tp: 107.0000 - val_fp: 128.0000 - val_tn: 618.0000 - val_fn: 266.0000 - val_accuracy: 0.4665 - val_precision: 0.4553 - val_recall: 0.2869 - val_auc: 0.6952 - val_prc: 0.4525\n",
      "Epoch 13/1000\n",
      "65/65 [==============================] - 7s 109ms/step - loss: 0.9138 - tp: 725.0000 - fp: 737.0000 - tn: 6985.0000 - fn: 3136.0000 - accuracy: 0.4776 - precision: 0.4959 - recall: 0.1878 - auc: 0.7036 - prc: 0.4748 - val_loss: 0.9052 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.6918 - val_prc: 0.4566\n",
      "Epoch 14/1000\n",
      "65/65 [==============================] - 7s 106ms/step - loss: 0.9112 - tp: 761.0000 - fp: 736.0000 - tn: 6986.0000 - fn: 3100.0000 - accuracy: 0.4815 - precision: 0.5084 - recall: 0.1971 - auc: 0.7063 - prc: 0.4774 - val_loss: 0.9216 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.6863 - val_prc: 0.4501\n",
      "Epoch 15/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.9123 - tp: 667.0000 - fp: 693.0000 - tn: 7029.0000 - fn: 3194.0000 - accuracy: 0.4918 - precision: 0.4904 - recall: 0.1728 - auc: 0.7061 - prc: 0.4735\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "65/65 [==============================] - 7s 105ms/step - loss: 0.9123 - tp: 667.0000 - fp: 693.0000 - tn: 7029.0000 - fn: 3194.0000 - accuracy: 0.4918 - precision: 0.4904 - recall: 0.1728 - auc: 0.7061 - prc: 0.4735 - val_loss: 0.9085 - val_tp: 168.0000 - val_fp: 196.0000 - val_tn: 550.0000 - val_fn: 205.0000 - val_accuracy: 0.4665 - val_precision: 0.4615 - val_recall: 0.4504 - val_auc: 0.6968 - val_prc: 0.4719\n",
      "Epoch 16/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9117 - tp: 595.0000 - fp: 629.0000 - tn: 7093.0000 - fn: 3266.0000 - accuracy: 0.4874 - precision: 0.4861 - recall: 0.1541 - auc: 0.7042 - prc: 0.4718 - val_loss: 0.9061 - val_tp: 167.0000 - val_fp: 198.0000 - val_tn: 548.0000 - val_fn: 206.0000 - val_accuracy: 0.4665 - val_precision: 0.4575 - val_recall: 0.4477 - val_auc: 0.6976 - val_prc: 0.4577\n",
      "Epoch 17/1000\n",
      "65/65 [==============================] - 7s 112ms/step - loss: 0.9090 - tp: 577.0000 - fp: 598.0000 - tn: 7124.0000 - fn: 3284.0000 - accuracy: 0.4893 - precision: 0.4911 - recall: 0.1494 - auc: 0.7078 - prc: 0.4785 - val_loss: 0.9070 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7026 - val_prc: 0.4627\n",
      "Epoch 18/1000\n",
      "65/65 [==============================] - 7s 111ms/step - loss: 0.9100 - tp: 584.0000 - fp: 582.0000 - tn: 7140.0000 - fn: 3277.0000 - accuracy: 0.4911 - precision: 0.5009 - recall: 0.1513 - auc: 0.7082 - prc: 0.4812 - val_loss: 0.9082 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.6999 - val_prc: 0.4607\n",
      "Epoch 19/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 7s 114ms/step - loss: 0.9096 - tp: 563.0000 - fp: 587.0000 - tn: 7135.0000 - fn: 3298.0000 - accuracy: 0.4893 - precision: 0.4896 - recall: 0.1458 - auc: 0.7091 - prc: 0.4805 - val_loss: 0.9139 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7016 - val_prc: 0.4619\n",
      "Epoch 20/1000\n",
      "65/65 [==============================] - 8s 124ms/step - loss: 0.9109 - tp: 513.0000 - fp: 589.0000 - tn: 7133.0000 - fn: 3348.0000 - accuracy: 0.4877 - precision: 0.4655 - recall: 0.1329 - auc: 0.7038 - prc: 0.4738 - val_loss: 0.9208 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7027 - val_prc: 0.4635\n",
      "Epoch 21/1000\n",
      "65/65 [==============================] - 7s 111ms/step - loss: 0.9123 - tp: 407.0000 - fp: 450.0000 - tn: 7272.0000 - fn: 3454.0000 - accuracy: 0.4877 - precision: 0.4749 - recall: 0.1054 - auc: 0.7022 - prc: 0.4717 - val_loss: 0.9048 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7030 - val_prc: 0.4737\n",
      "Epoch 22/1000\n",
      "65/65 [==============================] - 7s 107ms/step - loss: 0.9093 - tp: 522.0000 - fp: 490.0000 - tn: 7232.0000 - fn: 3339.0000 - accuracy: 0.4939 - precision: 0.5158 - recall: 0.1352 - auc: 0.7095 - prc: 0.4827 - val_loss: 0.9103 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.6999 - val_prc: 0.4637\n",
      "Epoch 23/1000\n",
      "65/65 [==============================] - 7s 111ms/step - loss: 0.9109 - tp: 517.0000 - fp: 570.0000 - tn: 7152.0000 - fn: 3344.0000 - accuracy: 0.4861 - precision: 0.4756 - recall: 0.1339 - auc: 0.7049 - prc: 0.4757 - val_loss: 0.9158 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.6991 - val_prc: 0.4665\n",
      "Epoch 24/1000\n",
      "65/65 [==============================] - 7s 106ms/step - loss: 0.9113 - tp: 498.0000 - fp: 503.0000 - tn: 7219.0000 - fn: 3363.0000 - accuracy: 0.4838 - precision: 0.4975 - recall: 0.1290 - auc: 0.7039 - prc: 0.4763 - val_loss: 0.9221 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7022 - val_prc: 0.4639\n",
      "Epoch 25/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.9098 - tp: 484.0000 - fp: 449.0000 - tn: 7273.0000 - fn: 3377.0000 - accuracy: 0.4903 - precision: 0.5188 - recall: 0.1254 - auc: 0.7091 - prc: 0.4841\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "65/65 [==============================] - 7s 109ms/step - loss: 0.9098 - tp: 484.0000 - fp: 449.0000 - tn: 7273.0000 - fn: 3377.0000 - accuracy: 0.4903 - precision: 0.5188 - recall: 0.1254 - auc: 0.7091 - prc: 0.4841 - val_loss: 0.9221 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7029 - val_prc: 0.4663\n",
      "Epoch 26/1000\n",
      "65/65 [==============================] - 7s 111ms/step - loss: 0.9090 - tp: 628.0000 - fp: 677.0000 - tn: 7045.0000 - fn: 3233.0000 - accuracy: 0.4867 - precision: 0.4812 - recall: 0.1627 - auc: 0.7081 - prc: 0.4795 - val_loss: 0.9223 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7029 - val_prc: 0.4661\n",
      "Epoch 27/1000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.9081 - tp: 635.0000 - fp: 600.0000 - tn: 7122.0000 - fn: 3226.0000 - accuracy: 0.4872 - precision: 0.5142 - recall: 0.1645 - auc: 0.7122 - prc: 0.4851 - val_loss: 0.9230 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7020 - val_prc: 0.4642\n",
      "Epoch 28/1000\n",
      "65/65 [==============================] - 8s 119ms/step - loss: 0.9093 - tp: 507.0000 - fp: 538.0000 - tn: 7184.0000 - fn: 3354.0000 - accuracy: 0.4854 - precision: 0.4852 - recall: 0.1313 - auc: 0.7080 - prc: 0.4787 - val_loss: 0.9230 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7016 - val_prc: 0.4617\n",
      "Epoch 29/1000\n",
      "65/65 [==============================] - 8s 125ms/step - loss: 0.9099 - tp: 502.0000 - fp: 509.0000 - tn: 7213.0000 - fn: 3359.0000 - accuracy: 0.4874 - precision: 0.4965 - recall: 0.1300 - auc: 0.7077 - prc: 0.4804 - val_loss: 0.9250 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7025 - val_prc: 0.4665\n",
      "Epoch 30/1000\n",
      "65/65 [==============================] - 7s 107ms/step - loss: 0.9091 - tp: 483.0000 - fp: 500.0000 - tn: 7222.0000 - fn: 3378.0000 - accuracy: 0.4903 - precision: 0.4914 - recall: 0.1251 - auc: 0.7086 - prc: 0.4775 - val_loss: 0.9259 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7016 - val_prc: 0.4616\n",
      "Epoch 31/1000\n",
      "65/65 [==============================] - 7s 110ms/step - loss: 0.9090 - tp: 491.0000 - fp: 477.0000 - tn: 7245.0000 - fn: 3370.0000 - accuracy: 0.4944 - precision: 0.5072 - recall: 0.1272 - auc: 0.7114 - prc: 0.4842 - val_loss: 0.9268 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7020 - val_prc: 0.4648\n",
      "Epoch 32/1000\n",
      "65/65 [==============================] - 7s 101ms/step - loss: 0.9078 - tp: 496.0000 - fp: 511.0000 - tn: 7211.0000 - fn: 3365.0000 - accuracy: 0.4869 - precision: 0.4926 - recall: 0.1285 - auc: 0.7095 - prc: 0.4800 - val_loss: 0.9263 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.6999 - val_prc: 0.4621\n",
      "Epoch 33/1000\n",
      "65/65 [==============================] - 7s 101ms/step - loss: 0.9078 - tp: 494.0000 - fp: 473.0000 - tn: 7249.0000 - fn: 3367.0000 - accuracy: 0.4882 - precision: 0.5109 - recall: 0.1279 - auc: 0.7094 - prc: 0.4823 - val_loss: 0.9258 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7003 - val_prc: 0.4601\n",
      "Epoch 34/1000\n",
      "65/65 [==============================] - 7s 103ms/step - loss: 0.9077 - tp: 481.0000 - fp: 487.0000 - tn: 7235.0000 - fn: 3380.0000 - accuracy: 0.4918 - precision: 0.4969 - recall: 0.1246 - auc: 0.7089 - prc: 0.4796 - val_loss: 0.9262 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7008 - val_prc: 0.4652\n",
      "Epoch 35/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.9090 - tp: 480.0000 - fp: 466.0000 - tn: 7256.0000 - fn: 3381.0000 - accuracy: 0.4877 - precision: 0.5074 - recall: 0.1243 - auc: 0.7092 - prc: 0.4840\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "65/65 [==============================] - 7s 100ms/step - loss: 0.9090 - tp: 480.0000 - fp: 466.0000 - tn: 7256.0000 - fn: 3381.0000 - accuracy: 0.4877 - precision: 0.5074 - recall: 0.1243 - auc: 0.7092 - prc: 0.4840 - val_loss: 0.9256 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7033 - val_prc: 0.4672\n",
      "Epoch 36/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9081 - tp: 485.0000 - fp: 507.0000 - tn: 7215.0000 - fn: 3376.0000 - accuracy: 0.4890 - precision: 0.4889 - recall: 0.1256 - auc: 0.7103 - prc: 0.4815 - val_loss: 0.9255 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7024 - val_prc: 0.4659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.9088 - tp: 487.0000 - fp: 489.0000 - tn: 7233.0000 - fn: 3374.0000 - accuracy: 0.4900 - precision: 0.4990 - recall: 0.1261 - auc: 0.7087 - prc: 0.4789 - val_loss: 0.9256 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7023 - val_prc: 0.4638\n",
      "Epoch 38/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9079 - tp: 471.0000 - fp: 477.0000 - tn: 7245.0000 - fn: 3390.0000 - accuracy: 0.4929 - precision: 0.4968 - recall: 0.1220 - auc: 0.7115 - prc: 0.4815 - val_loss: 0.9259 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7010 - val_prc: 0.4610\n",
      "Epoch 39/1000\n",
      "65/65 [==============================] - 7s 100ms/step - loss: 0.9104 - tp: 484.0000 - fp: 479.0000 - tn: 7243.0000 - fn: 3377.0000 - accuracy: 0.4867 - precision: 0.5026 - recall: 0.1254 - auc: 0.7054 - prc: 0.4801 - val_loss: 0.9260 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7017 - val_prc: 0.4633\n",
      "Epoch 40/1000\n",
      "65/65 [==============================] - 7s 103ms/step - loss: 0.9079 - tp: 493.0000 - fp: 460.0000 - tn: 7262.0000 - fn: 3368.0000 - accuracy: 0.4918 - precision: 0.5173 - recall: 0.1277 - auc: 0.7106 - prc: 0.4857 - val_loss: 0.9261 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7015 - val_prc: 0.4653\n",
      "Epoch 41/1000\n",
      "65/65 [==============================] - 7s 100ms/step - loss: 0.9085 - tp: 487.0000 - fp: 476.0000 - tn: 7246.0000 - fn: 3374.0000 - accuracy: 0.4916 - precision: 0.5057 - recall: 0.1261 - auc: 0.7082 - prc: 0.4811 - val_loss: 0.9262 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7029 - val_prc: 0.4666\n",
      "Epoch 42/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9083 - tp: 492.0000 - fp: 465.0000 - tn: 7257.0000 - fn: 3369.0000 - accuracy: 0.4887 - precision: 0.5141 - recall: 0.1274 - auc: 0.7112 - prc: 0.4838 - val_loss: 0.9264 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7015 - val_prc: 0.4643\n",
      "Epoch 43/1000\n",
      "65/65 [==============================] - 8s 117ms/step - loss: 0.9089 - tp: 483.0000 - fp: 479.0000 - tn: 7243.0000 - fn: 3378.0000 - accuracy: 0.4905 - precision: 0.5021 - recall: 0.1251 - auc: 0.7089 - prc: 0.4802 - val_loss: 0.9266 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7049 - val_prc: 0.4718\n",
      "Epoch 44/1000\n",
      "65/65 [==============================] - 7s 108ms/step - loss: 0.9085 - tp: 468.0000 - fp: 476.0000 - tn: 7246.0000 - fn: 3393.0000 - accuracy: 0.4864 - precision: 0.4958 - recall: 0.1212 - auc: 0.7080 - prc: 0.4767 - val_loss: 0.9265 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7027 - val_prc: 0.4651\n",
      "Epoch 45/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.9080 - tp: 473.0000 - fp: 488.0000 - tn: 7234.0000 - fn: 3388.0000 - accuracy: 0.4957 - precision: 0.4922 - recall: 0.1225 - auc: 0.7108 - prc: 0.4819\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "65/65 [==============================] - 7s 107ms/step - loss: 0.9080 - tp: 473.0000 - fp: 488.0000 - tn: 7234.0000 - fn: 3388.0000 - accuracy: 0.4957 - precision: 0.4922 - recall: 0.1225 - auc: 0.7108 - prc: 0.4819 - val_loss: 0.9266 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7045 - val_prc: 0.4716\n",
      "Epoch 46/1000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.9087 - tp: 454.0000 - fp: 469.0000 - tn: 7253.0000 - fn: 3407.0000 - accuracy: 0.4926 - precision: 0.4919 - recall: 0.1176 - auc: 0.7104 - prc: 0.4803 - val_loss: 0.9266 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7036 - val_prc: 0.4675\n",
      "Epoch 47/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9090 - tp: 492.0000 - fp: 476.0000 - tn: 7246.0000 - fn: 3369.0000 - accuracy: 0.4926 - precision: 0.5083 - recall: 0.1274 - auc: 0.7119 - prc: 0.4851 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7050 - val_prc: 0.4705\n",
      "Epoch 48/1000\n",
      "65/65 [==============================] - 7s 100ms/step - loss: 0.9094 - tp: 500.0000 - fp: 462.0000 - tn: 7260.0000 - fn: 3361.0000 - accuracy: 0.4851 - precision: 0.5198 - recall: 0.1295 - auc: 0.7091 - prc: 0.4835 - val_loss: 0.9268 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7060 - val_prc: 0.4697\n",
      "Epoch 49/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9085 - tp: 462.0000 - fp: 459.0000 - tn: 7263.0000 - fn: 3399.0000 - accuracy: 0.4900 - precision: 0.5016 - recall: 0.1197 - auc: 0.7084 - prc: 0.4810 - val_loss: 0.9268 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7055 - val_prc: 0.4679\n",
      "Epoch 50/1000\n",
      "65/65 [==============================] - 7s 105ms/step - loss: 0.9076 - tp: 502.0000 - fp: 483.0000 - tn: 7239.0000 - fn: 3359.0000 - accuracy: 0.4926 - precision: 0.5096 - recall: 0.1300 - auc: 0.7123 - prc: 0.4852 - val_loss: 0.9269 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7045 - val_prc: 0.4648\n",
      "Epoch 51/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9082 - tp: 488.0000 - fp: 489.0000 - tn: 7233.0000 - fn: 3373.0000 - accuracy: 0.4911 - precision: 0.4995 - recall: 0.1264 - auc: 0.7097 - prc: 0.4828 - val_loss: 0.9268 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7047 - val_prc: 0.4649\n",
      "Epoch 52/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9079 - tp: 472.0000 - fp: 449.0000 - tn: 7273.0000 - fn: 3389.0000 - accuracy: 0.4926 - precision: 0.5125 - recall: 0.1222 - auc: 0.7119 - prc: 0.4874 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4711\n",
      "Epoch 53/1000\n",
      "65/65 [==============================] - 6s 100ms/step - loss: 0.9075 - tp: 487.0000 - fp: 485.0000 - tn: 7237.0000 - fn: 3374.0000 - accuracy: 0.4843 - precision: 0.5010 - recall: 0.1261 - auc: 0.7091 - prc: 0.4807 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7052 - val_prc: 0.4678\n",
      "Epoch 54/1000\n",
      "65/65 [==============================] - 7s 108ms/step - loss: 0.9086 - tp: 492.0000 - fp: 493.0000 - tn: 7229.0000 - fn: 3369.0000 - accuracy: 0.4885 - precision: 0.4995 - recall: 0.1274 - auc: 0.7086 - prc: 0.4808 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7056 - val_prc: 0.4680\n",
      "Epoch 55/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - ETA: 0s - loss: 0.9082 - tp: 465.0000 - fp: 436.0000 - tn: 7286.0000 - fn: 3396.0000 - accuracy: 0.4893 - precision: 0.5161 - recall: 0.1204 - auc: 0.7103 - prc: 0.4844\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "65/65 [==============================] - 7s 107ms/step - loss: 0.9082 - tp: 465.0000 - fp: 436.0000 - tn: 7286.0000 - fn: 3396.0000 - accuracy: 0.4893 - precision: 0.5161 - recall: 0.1204 - auc: 0.7103 - prc: 0.4844 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 56/1000\n",
      "65/65 [==============================] - 7s 102ms/step - loss: 0.9087 - tp: 456.0000 - fp: 452.0000 - tn: 7270.0000 - fn: 3405.0000 - accuracy: 0.4942 - precision: 0.5022 - recall: 0.1181 - auc: 0.7101 - prc: 0.4813 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 57/1000\n",
      "65/65 [==============================] - 7s 106ms/step - loss: 0.9097 - tp: 474.0000 - fp: 506.0000 - tn: 7216.0000 - fn: 3387.0000 - accuracy: 0.4859 - precision: 0.4837 - recall: 0.1228 - auc: 0.7055 - prc: 0.4751 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7056 - val_prc: 0.4682\n",
      "Epoch 58/1000\n",
      "65/65 [==============================] - 7s 101ms/step - loss: 0.9078 - tp: 528.0000 - fp: 465.0000 - tn: 7257.0000 - fn: 3333.0000 - accuracy: 0.4890 - precision: 0.5317 - recall: 0.1368 - auc: 0.7124 - prc: 0.4875 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7056 - val_prc: 0.4682\n",
      "Epoch 59/1000\n",
      "65/65 [==============================] - 7s 105ms/step - loss: 0.9099 - tp: 451.0000 - fp: 457.0000 - tn: 7265.0000 - fn: 3410.0000 - accuracy: 0.4895 - precision: 0.4967 - recall: 0.1168 - auc: 0.7068 - prc: 0.4774 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 60/1000\n",
      "65/65 [==============================] - 7s 107ms/step - loss: 0.9097 - tp: 472.0000 - fp: 475.0000 - tn: 7247.0000 - fn: 3389.0000 - accuracy: 0.4874 - precision: 0.4984 - recall: 0.1222 - auc: 0.7081 - prc: 0.4815 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7056 - val_prc: 0.4682\n",
      "Epoch 61/1000\n",
      "65/65 [==============================] - 7s 102ms/step - loss: 0.9084 - tp: 474.0000 - fp: 482.0000 - tn: 7240.0000 - fn: 3387.0000 - accuracy: 0.4939 - precision: 0.4958 - recall: 0.1228 - auc: 0.7111 - prc: 0.4853 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7050 - val_prc: 0.4664\n",
      "Epoch 62/1000\n",
      "65/65 [==============================] - 7s 107ms/step - loss: 0.9086 - tp: 510.0000 - fp: 477.0000 - tn: 7245.0000 - fn: 3351.0000 - accuracy: 0.4880 - precision: 0.5167 - recall: 0.1321 - auc: 0.7110 - prc: 0.4827 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7056 - val_prc: 0.4682\n",
      "Epoch 63/1000\n",
      "65/65 [==============================] - 7s 115ms/step - loss: 0.9081 - tp: 489.0000 - fp: 501.0000 - tn: 7221.0000 - fn: 3372.0000 - accuracy: 0.4903 - precision: 0.4939 - recall: 0.1267 - auc: 0.7100 - prc: 0.4807 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7060 - val_prc: 0.4698\n",
      "Epoch 64/1000\n",
      "65/65 [==============================] - 7s 106ms/step - loss: 0.9082 - tp: 462.0000 - fp: 444.0000 - tn: 7278.0000 - fn: 3399.0000 - accuracy: 0.4929 - precision: 0.5099 - recall: 0.1197 - auc: 0.7095 - prc: 0.4821 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7051 - val_prc: 0.4676\n",
      "Epoch 65/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.9075 - tp: 522.0000 - fp: 486.0000 - tn: 7236.0000 - fn: 3339.0000 - accuracy: 0.4864 - precision: 0.5179 - recall: 0.1352 - auc: 0.7104 - prc: 0.4823\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "65/65 [==============================] - 7s 102ms/step - loss: 0.9075 - tp: 522.0000 - fp: 486.0000 - tn: 7236.0000 - fn: 3339.0000 - accuracy: 0.4864 - precision: 0.5179 - recall: 0.1352 - auc: 0.7104 - prc: 0.4823 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7056 - val_prc: 0.4680\n",
      "Epoch 66/1000\n",
      "65/65 [==============================] - 9s 133ms/step - loss: 0.9089 - tp: 492.0000 - fp: 485.0000 - tn: 7237.0000 - fn: 3369.0000 - accuracy: 0.4905 - precision: 0.5036 - recall: 0.1274 - auc: 0.7109 - prc: 0.4838 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7056 - val_prc: 0.4680\n",
      "Epoch 67/1000\n",
      "65/65 [==============================] - 8s 123ms/step - loss: 0.9085 - tp: 456.0000 - fp: 495.0000 - tn: 7227.0000 - fn: 3405.0000 - accuracy: 0.4864 - precision: 0.4795 - recall: 0.1181 - auc: 0.7085 - prc: 0.4809 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7053 - val_prc: 0.4678\n",
      "Epoch 68/1000\n",
      "65/65 [==============================] - 7s 109ms/step - loss: 0.9084 - tp: 471.0000 - fp: 456.0000 - tn: 7266.0000 - fn: 3390.0000 - accuracy: 0.4908 - precision: 0.5081 - recall: 0.1220 - auc: 0.7088 - prc: 0.4800 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7053 - val_prc: 0.4678\n",
      "Epoch 69/1000\n",
      "65/65 [==============================] - 7s 102ms/step - loss: 0.9088 - tp: 473.0000 - fp: 478.0000 - tn: 7244.0000 - fn: 3388.0000 - accuracy: 0.4916 - precision: 0.4974 - recall: 0.1225 - auc: 0.7095 - prc: 0.4804 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 70/1000\n",
      "65/65 [==============================] - 7s 105ms/step - loss: 0.9076 - tp: 491.0000 - fp: 479.0000 - tn: 7243.0000 - fn: 3370.0000 - accuracy: 0.4905 - precision: 0.5062 - recall: 0.1272 - auc: 0.7121 - prc: 0.4837 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 71/1000\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.9078 - tp: 447.0000 - fp: 461.0000 - tn: 7261.0000 - fn: 3414.0000 - accuracy: 0.4880 - precision: 0.4923 - recall: 0.1158 - auc: 0.7108 - prc: 0.4850 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 72/1000\n",
      "65/65 [==============================] - 7s 106ms/step - loss: 0.9078 - tp: 484.0000 - fp: 480.0000 - tn: 7242.0000 - fn: 3377.0000 - accuracy: 0.4893 - precision: 0.5021 - recall: 0.1254 - auc: 0.7093 - prc: 0.4784 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/1000\n",
      "65/65 [==============================] - 7s 105ms/step - loss: 0.9084 - tp: 485.0000 - fp: 463.0000 - tn: 7259.0000 - fn: 3376.0000 - accuracy: 0.4898 - precision: 0.5116 - recall: 0.1256 - auc: 0.7099 - prc: 0.4807 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 74/1000\n",
      "65/65 [==============================] - 7s 108ms/step - loss: 0.9074 - tp: 482.0000 - fp: 481.0000 - tn: 7241.0000 - fn: 3379.0000 - accuracy: 0.4861 - precision: 0.5005 - recall: 0.1248 - auc: 0.7106 - prc: 0.4824 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 75/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.9097 - tp: 429.0000 - fp: 504.0000 - tn: 7218.0000 - fn: 3432.0000 - accuracy: 0.4869 - precision: 0.4598 - recall: 0.1111 - auc: 0.7064 - prc: 0.4751\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "65/65 [==============================] - 8s 119ms/step - loss: 0.9097 - tp: 429.0000 - fp: 504.0000 - tn: 7218.0000 - fn: 3432.0000 - accuracy: 0.4869 - precision: 0.4598 - recall: 0.1111 - auc: 0.7064 - prc: 0.4751 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 76/1000\n",
      "65/65 [==============================] - 7s 105ms/step - loss: 0.9080 - tp: 493.0000 - fp: 460.0000 - tn: 7262.0000 - fn: 3368.0000 - accuracy: 0.4882 - precision: 0.5173 - recall: 0.1277 - auc: 0.7110 - prc: 0.4844 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 77/1000\n",
      "65/65 [==============================] - 8s 116ms/step - loss: 0.9080 - tp: 489.0000 - fp: 461.0000 - tn: 7261.0000 - fn: 3372.0000 - accuracy: 0.4893 - precision: 0.5147 - recall: 0.1267 - auc: 0.7116 - prc: 0.4834 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 78/1000\n",
      "65/65 [==============================] - 7s 109ms/step - loss: 0.9088 - tp: 457.0000 - fp: 462.0000 - tn: 7260.0000 - fn: 3404.0000 - accuracy: 0.4931 - precision: 0.4973 - recall: 0.1184 - auc: 0.7079 - prc: 0.4794 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 79/1000\n",
      "65/65 [==============================] - 8s 124ms/step - loss: 0.9074 - tp: 508.0000 - fp: 454.0000 - tn: 7268.0000 - fn: 3353.0000 - accuracy: 0.4911 - precision: 0.5281 - recall: 0.1316 - auc: 0.7148 - prc: 0.4921 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 80/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9082 - tp: 488.0000 - fp: 491.0000 - tn: 7231.0000 - fn: 3373.0000 - accuracy: 0.4838 - precision: 0.4985 - recall: 0.1264 - auc: 0.7084 - prc: 0.4841 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 81/1000\n",
      "65/65 [==============================] - 7s 101ms/step - loss: 0.9084 - tp: 463.0000 - fp: 485.0000 - tn: 7237.0000 - fn: 3398.0000 - accuracy: 0.4893 - precision: 0.4884 - recall: 0.1199 - auc: 0.7108 - prc: 0.4812 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 82/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9094 - tp: 454.0000 - fp: 477.0000 - tn: 7245.0000 - fn: 3407.0000 - accuracy: 0.4880 - precision: 0.4876 - recall: 0.1176 - auc: 0.7060 - prc: 0.4761 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 83/1000\n",
      "65/65 [==============================] - 7s 101ms/step - loss: 0.9091 - tp: 471.0000 - fp: 465.0000 - tn: 7257.0000 - fn: 3390.0000 - accuracy: 0.4877 - precision: 0.5032 - recall: 0.1220 - auc: 0.7081 - prc: 0.4801 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 84/1000\n",
      "65/65 [==============================] - 7s 108ms/step - loss: 0.9079 - tp: 482.0000 - fp: 451.0000 - tn: 7271.0000 - fn: 3379.0000 - accuracy: 0.4859 - precision: 0.5166 - recall: 0.1248 - auc: 0.7103 - prc: 0.4823 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 85/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.9085 - tp: 466.0000 - fp: 482.0000 - tn: 7240.0000 - fn: 3395.0000 - accuracy: 0.4918 - precision: 0.4916 - recall: 0.1207 - auc: 0.7105 - prc: 0.4805\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
      "65/65 [==============================] - 7s 110ms/step - loss: 0.9085 - tp: 466.0000 - fp: 482.0000 - tn: 7240.0000 - fn: 3395.0000 - accuracy: 0.4918 - precision: 0.4916 - recall: 0.1207 - auc: 0.7105 - prc: 0.4805 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 86/1000\n",
      "65/65 [==============================] - 7s 101ms/step - loss: 0.9087 - tp: 439.0000 - fp: 461.0000 - tn: 7261.0000 - fn: 3422.0000 - accuracy: 0.4900 - precision: 0.4878 - recall: 0.1137 - auc: 0.7087 - prc: 0.4790 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 87/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9086 - tp: 486.0000 - fp: 468.0000 - tn: 7254.0000 - fn: 3375.0000 - accuracy: 0.4898 - precision: 0.5094 - recall: 0.1259 - auc: 0.7099 - prc: 0.4836 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 88/1000\n",
      "65/65 [==============================] - 7s 114ms/step - loss: 0.9084 - tp: 482.0000 - fp: 472.0000 - tn: 7250.0000 - fn: 3379.0000 - accuracy: 0.4908 - precision: 0.5052 - recall: 0.1248 - auc: 0.7118 - prc: 0.4841 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 89/1000\n",
      "65/65 [==============================] - 7s 104ms/step - loss: 0.9086 - tp: 439.0000 - fp: 482.0000 - tn: 7240.0000 - fn: 3422.0000 - accuracy: 0.4872 - precision: 0.4767 - recall: 0.1137 - auc: 0.7078 - prc: 0.4782 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 90/1000\n",
      "65/65 [==============================] - 7s 100ms/step - loss: 0.9084 - tp: 476.0000 - fp: 507.0000 - tn: 7215.0000 - fn: 3385.0000 - accuracy: 0.4893 - precision: 0.4842 - recall: 0.1233 - auc: 0.7099 - prc: 0.4811 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/1000\n",
      "65/65 [==============================] - 7s 103ms/step - loss: 0.9089 - tp: 472.0000 - fp: 482.0000 - tn: 7240.0000 - fn: 3389.0000 - accuracy: 0.4867 - precision: 0.4948 - recall: 0.1222 - auc: 0.7075 - prc: 0.4778 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 92/1000\n",
      "65/65 [==============================] - 7s 102ms/step - loss: 0.9086 - tp: 471.0000 - fp: 492.0000 - tn: 7230.0000 - fn: 3390.0000 - accuracy: 0.4931 - precision: 0.4891 - recall: 0.1220 - auc: 0.7097 - prc: 0.4808 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 93/1000\n",
      "65/65 [==============================] - 7s 108ms/step - loss: 0.9082 - tp: 506.0000 - fp: 491.0000 - tn: 7231.0000 - fn: 3355.0000 - accuracy: 0.4908 - precision: 0.5075 - recall: 0.1311 - auc: 0.7118 - prc: 0.4845 - val_loss: 0.9267 - val_tp: 174.0000 - val_fp: 199.0000 - val_tn: 547.0000 - val_fn: 199.0000 - val_accuracy: 0.4665 - val_precision: 0.4665 - val_recall: 0.4665 - val_auc: 0.7059 - val_prc: 0.4698\n",
      "Epoch 94/1000\n",
      "11/65 [====>.........................] - ETA: 5s - loss: 0.8668 - tp: 43.0000 - fp: 51.0000 - tn: 1269.0000 - fn: 617.0000 - accuracy: 0.4606 - precision: 0.4574 - recall: 0.0652 - auc: 0.7060 - prc: 0.4639"
     ]
    }
   ],
   "source": [
    "model,history= basic_lstm(input_dim, feature_size)\n",
    "model.save('./saveModel/LSTM_3to1.h5')\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history_dict['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-method",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# “bo”代表 \"蓝点\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b代表“蓝色实线”\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # 清除数字\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(2,2,n+1)\n",
    "        plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == 'auc':\n",
    "            plt.ylim([0.8,1])\n",
    "        else:\n",
    "            plt.ylim([0,1])\n",
    "\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-chorus",
   "metadata": {},
   "source": [
    "### Note: That the validation curve generally performs better than the training curve. This is mainly caused by the fact that the dropout layer is not active when evaluating the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-couple",
   "metadata": {},
   "source": [
    "\n",
    "### Evaluate metrics \n",
    "### You can use a confusion matrix to summarize the actual vs. predicted labels where the X axis is the predicted label  and the Y axis is the actual label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_baseline = model.predict(X_train, batch_size=BATCH_SIZE)\n",
    "test_predictions_baseline = model.predict(X_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-yeast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-result",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = model.evaluate(X_test, y_test,\n",
    "                                  batch_size=BATCH_SIZE, verbose=1)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "#plot_cm(y_test, test_predictions_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-window",
   "metadata": {},
   "source": [
    "# 绘制ROC曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import label_binarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "#同时也是分类得分y_score\n",
    "#概率矩阵P和标签矩阵L分别对应代码中的y_score和y_one_hot：\n",
    "yhat = model.predict(X_test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_count = {}\n",
    "dict_count['跌']=0\n",
    "dict_count['涨']=0\n",
    "dict_count['平']=0\n",
    "for i in range(len(y_test)):\n",
    "    if(y_test[i][0] ==1):\n",
    "        dict_count['跌'] += 1\n",
    "    if(y_test[i][1] == 1):\n",
    "        dict_count['平'] += 1\n",
    "    if(y_test[i][2] == 1):\n",
    "        dict_count['涨'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算属于各个类别的概率，返回值的shape = [n_samples, n_classes]\n",
    "y_score = model.predict(X_test)\n",
    "# 1、调用函数计算micro类型的AUC\n",
    "print('调用函数auc：', metrics.roc_auc_score(y_test, y_score, average='micro'))\n",
    "# 2、手动计算micro类型的AUC\n",
    "#首先将矩阵y_one_hot和y_score展开，然后计算假正例率FPR和真正例率TPR\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test.ravel(),y_score.ravel())\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print('手动计算auc：', auc)\n",
    "#绘图\n",
    "mpl.rcParams['font.sans-serif'] = u'SimHei'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "#FPR就是横坐标,TPR就是纵坐标\n",
    "plt.plot(fpr, tpr, c = 'r', lw = 2, alpha = 0.7, label = u'AUC=%.3f' % auc)\n",
    "plt.plot((0, 1), (0, 1), c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.xlabel('False Positive Rate', fontsize=13)\n",
    "plt.ylabel('True Positive Rate', fontsize=13)\n",
    "plt.grid(b=True, ls=':')\n",
    "plt.legend(loc='lower right', fancybox=True, framealpha=0.8, fontsize=12)\n",
    "plt.title(u'mtj_june数据集分类后的ROC和AUC', fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-collect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-ottawa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-condition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-particle",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, average_precision_score,precision_score,f1_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_0_1(y):\n",
    "    res = []\n",
    "    for i in range(y.shape[0]):\n",
    "        if(y[i][0] > y[i][1] and y[i][0] > y[i][2]):\n",
    "            res.append(-1) #跌\n",
    "        if(y[i][1] > y[i][0] and y[i][1] > y[i][2]):\n",
    "            res.append(0) #平\n",
    "        if(y[i][2] > y[i][0] and y[i][2] > y[i][1]):\n",
    "            res.append(1) #涨\n",
    "    return np.array(res)\n",
    "\n",
    "def result_to_0_1(y):\n",
    "        if(tf.is_tensor(y)):\n",
    "            y = y.numpy()\n",
    "            for i in range(y.shape[0]):\n",
    "                max_index = 0\n",
    "                if(y[i][max_index] < y[i][1]):\n",
    "                    max_index = 1\n",
    "                if(y[i][max_index] < y[i][2]):\n",
    "                    max_index = 2\n",
    "                list_temp = [0,1,2]\n",
    "                list_temp.pop(max_index)\n",
    "                y[i][max_index] = 1\n",
    "                y[i][list_temp[0]] = 0\n",
    "                y[i][list_temp[1]] = 0\n",
    "        else:\n",
    "            for i in range(y.shape[0]):\n",
    "                max_index = 0\n",
    "                if(y[i][max_index] < y[i][1]):\n",
    "                    max_index = 1\n",
    "                if(y[i][max_index] < y[i][2]):\n",
    "                    max_index = 2\n",
    "                list_temp = [0,1,2]\n",
    "                list_temp.pop(max_index)\n",
    "                y[i][max_index] = 1\n",
    "                y[i][list_temp[0]] = 0\n",
    "                y[i][list_temp[1]] = 0\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-advertiser",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = result_to_0_1(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = to_0_1(yhat)\n",
    "y_true = to_0_1(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pre)\n",
    "conf_matrix = pd.DataFrame(cm, index=['跌','平','涨'], columns=['跌','平','涨'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot size setting\n",
    "fig, ax = plt.subplots(figsize = (9,6))\n",
    "sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 19},fmt='.20g', cmap=\"Blues\")\n",
    "plt.ylabel('True label', fontsize=18)\n",
    "plt.xlabel('Predicted label', fontsize=18)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.savefig('confusion.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------Weighted------')\n",
    "print('Weighted precision', precision_score(y_true, y_pre, average='weighted'))\n",
    "print('Weighted recall', recall_score(y_true, y_pre, average='weighted'))\n",
    "print('Weighted f1-score', f1_score(y_true, y_pre, average='weighted'))\n",
    "print('------Macro------')\n",
    "print('Macro precision', precision_score(y_true, y_pre, average='macro'))\n",
    "print('Macro recall', recall_score(y_true, y_pre, average='macro'))\n",
    "print('Macro f1-score', f1_score(y_true, y_pre, average='macro'))\n",
    "print('------Micro------')\n",
    "print('Micro precision', precision_score(y_true, y_pre, average='micro'))\n",
    "print('Micro recall', recall_score(y_true, y_pre, average='micro'))\n",
    "print('Micro f1-score', f1_score(y_true, y_pre, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "# 计算每一类的ROC\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = 3\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "# Compute micro-average ROC curve and ROC area（方法二）\n",
    "fpr[\"weighted\"], tpr[\"weighted\"], _ = roc_curve(\n",
    "    y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"weighted\"] = metrics.auc(fpr[\"weighted\"], tpr[\"weighted\"])\n",
    "\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area（方法一）\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = metrics.auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "lw = 2\n",
    "plt.figure()\n",
    "# plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "#          label='micro-average ROC curve (area = {0:0.4f})'\n",
    "#          ''.format(roc_auc[\"micro\"]),\n",
    "#          color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.4f})'\n",
    "         ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "plt.plot(fpr[\"weighted\"], tpr[\"weighted\"],\n",
    "         label='weighted-average ROC curve (area = {0:0.4f})'\n",
    "         ''.format(roc_auc[\"weighted\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "# # 计算每一类的ROC\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "# n_classes=3\n",
    "# for i in range(n_classes):\n",
    "#     fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "#     roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "# # Compute micro-average ROC curve and ROC area（方法二）\n",
    "# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "# # Compute macro-average ROC curve and ROC area（方法一）\n",
    "# # First aggregate all false positive rates\n",
    "# all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "# # Then interpolate all ROC curves at this points\n",
    "# mean_tpr = np.zeros_like(all_fpr)\n",
    "# for i in range(n_classes):\n",
    "#     mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "# # Finally average it and compute AUC\n",
    "# mean_tpr /= n_classes\n",
    "# fpr[\"macro\"] = all_fpr\n",
    "# tpr[\"macro\"] = mean_tpr\n",
    "# roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# # Plot all ROC curves\n",
    "# lw=2\n",
    "# plt.figure()\n",
    "# plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "#          label='micro-average ROC curve (area = {0:0.4f})'\n",
    "#                ''.format(roc_auc[\"micro\"]),\n",
    "#          color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "# plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "#          label='macro-average ROC curve (area = {0:0.4f})'\n",
    "#                ''.format(roc_auc[\"macro\"]),\n",
    "#          color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "# colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "# for i, color in zip(range(n_classes), colors):\n",
    "#     plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "#              label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "#              ''.format(i, roc_auc[i]))\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-valuation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-dialogue",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-cisco",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-grant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-medline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

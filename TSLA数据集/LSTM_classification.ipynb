{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "pregnant-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from numpy import *\n",
    "from math import sqrt\n",
    "from pandas import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Bidirectional, Activation\n",
    "from tensorflow.keras.layers import BatchNormalization, Embedding, TimeDistributed, LeakyReLU\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics as ms\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from pickle import load\n",
    "from sklearn import metrics as ms\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, average_precision_score, f1_score, recall_score\n",
    "\n",
    "# X_train = np.load(\"./saveData/IBM/X_train.npy\", allow_pickle=True)\n",
    "# y_train = np.load(\"./saveData/IBM/y_train.npy\", allow_pickle=True)\n",
    "# X_test = np.load(\"./saveData/IBM/X_test.npy\", allow_pickle=True)\n",
    "# y_test = np.load(\"./saveData/IBM/y_test.npy\", allow_pickle=True)\n",
    "# X_val = np.load(\"./saveData/IBM/X_val.npy\", allow_pickle=True)\n",
    "# y_val = np.load(\"./saveData/IBM/y_val.npy\", allow_pickle=True)\n",
    "\n",
    "X_train = np.load(\"./saveData/TSLA/X_train.npy\", allow_pickle=True)\n",
    "y_train = np.load(\"./saveData/TSLA/y_train.npy\", allow_pickle=True)\n",
    "X_test = np.load(\"./saveData/TSLA/X_test.npy\", allow_pickle=True)\n",
    "y_test = np.load(\"./saveData/TSLA/y_test.npy\", allow_pickle=True)\n",
    "X_val = np.load(\"./saveData/TSLA/X_val.npy\", allow_pickle=True)\n",
    "y_val = np.load(\"./saveData/TSLA/y_val.npy\", allow_pickle=True)\n",
    "\n",
    "# X_train = np.load(\"./saveData/S&P500/X_train.npy\", allow_pickle=True)\n",
    "# y_train = np.load(\"./saveData/S&P500/y_train.npy\", allow_pickle=True)\n",
    "# X_test = np.load(\"./saveData/S&P500/X_test.npy\", allow_pickle=True)\n",
    "# y_test = np.load(\"./saveData/S&P500/y_test.npy\", allow_pickle=True)\n",
    "# X_val = np.load(\"./saveData/S&P500/X_val.npy\", allow_pickle=True)\n",
    "# y_val = np.load(\"./saveData/S&P500/y_val.npy\", allow_pickle=True)\n",
    "\n",
    "# X_train = np.load(\"./saveData/PAICC/X_train.npy\", allow_pickle=True)\n",
    "# y_train = np.load(\"./saveData/PAICC/y_train.npy\", allow_pickle=True)\n",
    "# X_test = np.load(\"./saveData/PAICC/X_test.npy\", allow_pickle=True)\n",
    "# y_test = np.load(\"./saveData/PAICC/y_test.npy\", allow_pickle=True)\n",
    "# X_val = np.load(\"./saveData/PAICC/X_val.npy\", allow_pickle=True)\n",
    "# y_val = np.load(\"./saveData/PAICC/y_val.npy\", allow_pickle=True)\n",
    "\n",
    "# X_train = np.load(\"./saveData/X_train.npy\", allow_pickle=True)\n",
    "# y_train = np.load(\"./saveData/y_train.npy\", allow_pickle=True)\n",
    "# X_test = np.load(\"./saveData/X_test.npy\", allow_pickle=True)\n",
    "# y_test = np.load(\"./saveData/y_test.npy\", allow_pickle=True)\n",
    "# X_val = np.load(\"./saveData/X_val.npy\", allow_pickle=True)\n",
    "# y_val = np.load(\"./saveData/y_val.npy\", allow_pickle=True)\n",
    "\n",
    "\n",
    "# X_train = np.load(\"./saveData/MSFT/X_train.npy\", allow_pickle=True)\n",
    "# y_train = np.load(\"./saveData/MSFT/y_train.npy\", allow_pickle=True)\n",
    "# X_test = np.load(\"./saveData/MSFT/X_test.npy\", allow_pickle=True)\n",
    "# y_test = np.load(\"./saveData/MSFT/y_test.npy\", allow_pickle=True)\n",
    "# X_val = np.load(\"./saveData/MSFT/X_val.npy\", allow_pickle=True)\n",
    "# y_val = np.load(\"./saveData/MSFT/y_val.npy\", allow_pickle=True)\n",
    "\n",
    "# X_train = np.load(\"./saveData/SSE/X_train.npy\", allow_pickle=True)\n",
    "# y_train = np.load(\"./saveData/SSE/y_train.npy\", allow_pickle=True)\n",
    "# X_test = np.load(\"./saveData/SSE/X_test.npy\", allow_pickle=True)\n",
    "# y_test = np.load(\"./saveData/SSE/y_test.npy\", allow_pickle=True)\n",
    "# X_val = np.load(\"./saveData/SSE/X_val.npy\", allow_pickle=True)\n",
    "# y_val = np.load(\"./saveData/SSE/y_val.npy\", allow_pickle=True)\n",
    "\n",
    "# X_train = np.load(\"./saveData/IBM/X_train.npy\", allow_pickle=True)\n",
    "# y_train = np.load(\"./saveData/IBM/y_train.npy\", allow_pickle=True)\n",
    "# X_test = np.load(\"./saveData/IBM/X_test.npy\", allow_pickle=True)\n",
    "# y_test = np.load(\"./saveData/IBM/y_test.npy\", allow_pickle=True)\n",
    "# X_val = np.load(\"./saveData/IBM/X_val.npy\", allow_pickle=True)\n",
    "# y_val = np.load(\"./saveData/IBM/y_val.npy\", allow_pickle=True)\n",
    "# yc_train = np.load(\"./saveData/yc_train.npy\", allow_pickle=True)\n",
    "# yc_test = np.load(\"./saveData/yc_test.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "graduate-grade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       ...,\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "driven-couple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'跌': 779, '涨': 857, '平': 444}\n"
     ]
    }
   ],
   "source": [
    "dict_count = {}\n",
    "dict_count['跌']=0\n",
    "dict_count['涨']=0\n",
    "dict_count['平']=0\n",
    "for i in range(len(y_train)):\n",
    "    if(y_train[i][0] ==1):\n",
    "        dict_count['跌'] += 1\n",
    "    if(y_train[i][1] == 1):\n",
    "        dict_count['平'] += 1\n",
    "    if(y_train[i][2] == 1):\n",
    "        dict_count['涨'] += 1\n",
    "print(dict_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "demonstrated-prison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'跌': 91, '涨': 96, '平': 14}\n"
     ]
    }
   ],
   "source": [
    "dict_count = {}\n",
    "dict_count['跌']=0\n",
    "dict_count['涨']=0\n",
    "dict_count['平']=0\n",
    "for i in range(len(y_val)):\n",
    "    if(y_val[i][0] ==1):\n",
    "        dict_count['跌'] += 1\n",
    "    if(y_val[i][1] == 1):\n",
    "        dict_count['平'] += 1\n",
    "    if(y_val[i][2] == 1):\n",
    "        dict_count['涨'] += 1\n",
    "print(dict_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "military-oriental",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'跌': 174, '涨': 224, '平': 5}\n"
     ]
    }
   ],
   "source": [
    "dict_count = {}\n",
    "dict_count['跌']=0\n",
    "dict_count['涨']=0\n",
    "dict_count['平']=0\n",
    "for i in range(len(y_test)):\n",
    "    if(y_test[i][0] ==1):\n",
    "        dict_count['跌'] += 1\n",
    "    if(y_test[i][1] == 1):\n",
    "        dict_count['平'] += 1\n",
    "    if(y_test[i][2] == 1):\n",
    "        dict_count['涨'] += 1\n",
    "print(dict_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-bathroom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "recreational-pension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'跌': 174, '涨': 224, '平': 5}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "elegant-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "average-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train[0:5001]\n",
    "# y_train = y_train[0:5001]\n",
    "# X_test = X_test[0:5001]\n",
    "# y_test = y_test[0:5001]\n",
    "# X_val = X_val[0:5001]\n",
    "# y_val = y_val[0:5001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "threatened-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "min_delta_val = 0.0001\n",
    "lr_cb = ReduceLROnPlateau(monitor = 'val_loss',  \n",
    "                          factor = 0.5, min_delta = min_delta_val, patience = 10, verbose = 1)\n",
    "es_cb = EarlyStopping(monitor = 'accuracy', \n",
    "                      min_delta=min_delta_val, patience = 30, verbose = 1, restore_best_weights = True, mode='max')\n",
    "\n",
    "callbacks_model = [lr_cb, es_cb]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "voluntary-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Parameters\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 60\n",
    "N_EPOCH = 1000\n",
    "dropout = 0.2\n",
    "input_dim = X_train.shape[1]\n",
    "feature_size = X_train.shape[2]\n",
    "#做3分类\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "#output_dim = 3\n",
    "\n",
    "# METRICS = [\n",
    "#       keras.metrics.TruePositives(name='tp'),\n",
    "#       keras.metrics.FalsePositives(name='fp'),\n",
    "#       keras.metrics.TrueNegatives(name='tn'),\n",
    "#       keras.metrics.FalseNegatives(name='fn'), \n",
    "#       keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "#       keras.metrics.Precision(name='precision'),\n",
    "#       keras.metrics.Recall(name='recall'),\n",
    "#       keras.metrics.AUC(name='auc'),\n",
    "#       keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "# ]\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def basic_lstm(input_dim, feature_size):\n",
    "    print(\"model dim: \", input_dim, output_dim)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=(input_dim,feature_size), batch_size=None))\n",
    "    #model.add(tf.keras.layers.GaussianNoise(stddev=0.2))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "    #model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr = LR),metrics=METRICS)\n",
    "#     model = Sequential()\n",
    "#     model.add(Bidirectional(LSTM(units= 128), input_shape=(input_dim, feature_size)))\n",
    "#     model.add(Dense(64))\n",
    "#     model.add(Dense(units=output_dim,activation='softmax'))\n",
    "#     model.compile(optimizer=Adam(lr = LR), loss='mse')\n",
    "    history = model.fit(X_train, y_train, epochs=N_EPOCH, batch_size=BATCH_SIZE, validation_data=(X_val, y_val),\n",
    "                        verbose=1, shuffle=False , callbacks=callbacks_model)\n",
    "    #, callbacks=callbacks_model\n",
    "\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='validation')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "    return model,history\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cooperative-tourism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2080, 30, 16)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "endangered-awareness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2080, 3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "unlike-pleasure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 30, 16)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "engaged-listening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "wooden-scheme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       ...,\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "sharing-component",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.99981074, -0.99987062, -0.99979261, ..., -0.05576173,\n",
       "         -0.9019006 , -0.99477366],\n",
       "        [-0.99952685, -0.99978585, -0.99987557, ..., -0.02915401,\n",
       "         -0.94106849, -0.99584901],\n",
       "        [-1.        , -0.99993754, -1.        , ..., -0.0329735 ,\n",
       "         -0.96079286, -0.99481336],\n",
       "        ...,\n",
       "        [-0.99936463, -0.99951817, -0.99939166, ..., -0.32966625,\n",
       "         -0.78886345, -0.99896471],\n",
       "        [-0.99916185, -0.99924156, -0.99920731, ..., -0.11818836,\n",
       "         -0.81166645, -0.9982161 ],\n",
       "        [-0.99887346, -0.99893818, -0.9988801 , ...,  0.16512153,\n",
       "         -0.79154759, -0.99604412]],\n",
       "\n",
       "       [[-0.99952685, -0.99978585, -0.99987557, ..., -0.02915401,\n",
       "         -0.94106849, -0.99584901],\n",
       "        [-1.        , -0.99993754, -1.        , ..., -0.0329735 ,\n",
       "         -0.96079286, -0.99481336],\n",
       "        [-0.99995043, -1.        , -0.99991704, ...,  0.05717583,\n",
       "         -0.97854479, -0.99428401],\n",
       "        ...,\n",
       "        [-0.99916185, -0.99924156, -0.99920731, ..., -0.11818836,\n",
       "         -0.81166645, -0.9982161 ],\n",
       "        [-0.99887346, -0.99893818, -0.9988801 , ...,  0.16512153,\n",
       "         -0.79154759, -0.99604412],\n",
       "        [-0.99880587, -0.99869727, -0.99870958, ...,  0.340815  ,\n",
       "         -0.7462141 , -0.99252228]],\n",
       "\n",
       "       [[-1.        , -0.99993754, -1.        , ..., -0.0329735 ,\n",
       "         -0.96079286, -0.99481336],\n",
       "        [-0.99995043, -1.        , -0.99991704, ...,  0.05717583,\n",
       "         -0.97854479, -0.99428401],\n",
       "        [-0.99975216, -0.99942894, -0.99969122, ...,  0.45841227,\n",
       "         -0.95267909, -0.99233808],\n",
       "        ...,\n",
       "        [-0.99887346, -0.99893818, -0.9988801 , ...,  0.16512153,\n",
       "         -0.79154759, -0.99604412],\n",
       "        [-0.99880587, -0.99869727, -0.99870958, ...,  0.340815  ,\n",
       "         -0.7462141 , -0.99252228],\n",
       "        [-0.99844087, -0.99864373, -0.99914279, ...,  0.08668823,\n",
       "         -0.7781995 , -0.99644919]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.85392803, -0.85366584, -0.85306716, ..., -0.06817139,\n",
       "         -0.32733695, -0.42181705],\n",
       "        [-0.85409475, -0.85301   , -0.85219613, ...,  0.04845042,\n",
       "         -0.37007555, -0.41354458],\n",
       "        [-0.85280599, -0.84983348, -0.84939407, ...,  0.29107968,\n",
       "         -0.37910397, -0.40065721],\n",
       "        ...,\n",
       "        [-0.87316937, -0.86265111, -0.87291199, ..., -0.25938807,\n",
       "         -0.36309983, -0.43243658],\n",
       "        [-0.86422913, -0.86479259, -0.86949699, ..., -0.23792019,\n",
       "         -0.36370019, -0.44777205],\n",
       "        [-0.86276011, -0.85851538, -0.86170377, ..., -0.02858819,\n",
       "         -0.43189447, -0.42999742]],\n",
       "\n",
       "       [[-0.85409475, -0.85301   , -0.85219613, ...,  0.04845042,\n",
       "         -0.37007555, -0.41354458],\n",
       "        [-0.85280599, -0.84983348, -0.84939407, ...,  0.29107968,\n",
       "         -0.37910397, -0.40065721],\n",
       "        [-0.84778162, -0.84490363, -0.84581777, ...,  0.4184911 ,\n",
       "         -0.34975365, -0.41802034],\n",
       "        ...,\n",
       "        [-0.86422913, -0.86479259, -0.86949699, ..., -0.23792019,\n",
       "         -0.36370019, -0.44777205],\n",
       "        [-0.86276011, -0.85851538, -0.86170377, ..., -0.02858819,\n",
       "         -0.43189447, -0.42999742],\n",
       "        [-0.85614056, -0.85719034, -0.85854684, ...,  0.08173597,\n",
       "         -0.50597413, -0.44126828]],\n",
       "\n",
       "       [[-0.85280599, -0.84983348, -0.84939407, ...,  0.29107968,\n",
       "         -0.37910397, -0.40065721],\n",
       "        [-0.84778162, -0.84490363, -0.84581777, ...,  0.4184911 ,\n",
       "         -0.34975365, -0.41802034],\n",
       "        [-0.85435612, -0.85246571, -0.85472628, ..., -0.14688714,\n",
       "         -0.42842998, -0.43233572],\n",
       "        ...,\n",
       "        [-0.86276011, -0.85851538, -0.86170377, ..., -0.02858819,\n",
       "         -0.43189447, -0.42999742],\n",
       "        [-0.85614056, -0.85719034, -0.85854684, ...,  0.08173597,\n",
       "         -0.50597413, -0.44126828],\n",
       "        [-0.8704206 , -0.86793341, -0.87074132, ..., -0.29168529,\n",
       "         -0.49153829, -0.46211819]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-swing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-decision",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model dim:  30 3\n",
      "Epoch 1/1000\n",
      "35/35 [==============================] - 6s 184ms/step - loss: 1.0214 - tp: 326.0000 - fp: 409.0000 - tn: 3751.0000 - fn: 1754.0000 - accuracy: 0.4255 - precision: 0.4435 - recall: 0.1567 - auc: 0.6506 - prc: 0.4349 - val_loss: 0.9169 - val_tp: 91.0000 - val_fp: 110.0000 - val_tn: 292.0000 - val_fn: 110.0000 - val_accuracy: 0.4527 - val_precision: 0.4527 - val_recall: 0.4527 - val_auc: 0.6998 - val_prc: 0.4612\n",
      "Epoch 2/1000\n",
      "35/35 [==============================] - 2s 68ms/step - loss: 1.1436 - tp: 74.0000 - fp: 190.0000 - tn: 3970.0000 - fn: 2006.0000 - accuracy: 0.3562 - precision: 0.2803 - recall: 0.0356 - auc: 0.5363 - prc: 0.3449 - val_loss: 0.8993 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7036 - val_prc: 0.4677\n",
      "Epoch 3/1000\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 1.1418 - tp: 25.0000 - fp: 86.0000 - tn: 4074.0000 - fn: 2055.0000 - accuracy: 0.3909 - precision: 0.2252 - recall: 0.0120 - auc: 0.5552 - prc: 0.3580 - val_loss: 0.9594 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7050 - val_prc: 0.4783\n",
      "Epoch 4/1000\n",
      "35/35 [==============================] - 2s 65ms/step - loss: 1.0880 - tp: 0.0000e+00 - fp: 3.0000 - tn: 4157.0000 - fn: 2080.0000 - accuracy: 0.3812 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5628 - prc: 0.3700 - val_loss: 0.9684 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7046 - val_prc: 0.4717\n",
      "Epoch 5/1000\n",
      "35/35 [==============================] - 2s 61ms/step - loss: 1.0773 - tp: 0.0000e+00 - fp: 3.0000 - tn: 4157.0000 - fn: 2080.0000 - accuracy: 0.3832 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5729 - prc: 0.3694 - val_loss: 0.9657 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7070 - val_prc: 0.4627\n",
      "Epoch 6/1000\n",
      "35/35 [==============================] - 2s 68ms/step - loss: 1.0753 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.4000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5783 - prc: 0.3752 - val_loss: 0.9658 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7078 - val_prc: 0.4833\n",
      "Epoch 7/1000\n",
      "35/35 [==============================] - 3s 82ms/step - loss: 1.0755 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.3962 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5746 - prc: 0.3775 - val_loss: 0.9668 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7070 - val_prc: 0.4749\n",
      "Epoch 8/1000\n",
      "35/35 [==============================] - 3s 77ms/step - loss: 1.0741 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.3938 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5760 - prc: 0.3779 - val_loss: 0.9670 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7029 - val_prc: 0.4781\n",
      "Epoch 9/1000\n",
      "35/35 [==============================] - 2s 67ms/step - loss: 1.0746 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.4038 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5756 - prc: 0.3786 - val_loss: 0.9676 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7068 - val_prc: 0.4819\n",
      "Epoch 10/1000\n",
      "35/35 [==============================] - 2s 67ms/step - loss: 1.0739 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.3938 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5739 - prc: 0.3769 - val_loss: 0.9670 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7138 - val_prc: 0.4890\n",
      "Epoch 11/1000\n",
      "35/35 [==============================] - 3s 71ms/step - loss: 1.0727 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.4120 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5808 - prc: 0.3816 - val_loss: 0.9665 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7098 - val_prc: 0.4880\n",
      "Epoch 12/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 1.0725 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.4048 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5786 - prc: 0.3831\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "35/35 [==============================] - 2s 63ms/step - loss: 1.0725 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.4048 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5786 - prc: 0.3831 - val_loss: 0.9671 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7093 - val_prc: 0.4826\n",
      "Epoch 13/1000\n",
      "35/35 [==============================] - 2s 63ms/step - loss: 1.0670 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.4067 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5900 - prc: 0.3836 - val_loss: 0.9680 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7068 - val_prc: 0.4774\n",
      "Epoch 14/1000\n",
      "35/35 [==============================] - 2s 67ms/step - loss: 1.0646 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.4187 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5990 - prc: 0.3861 - val_loss: 0.9615 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4826 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7159 - val_prc: 0.4892\n",
      "Epoch 15/1000\n",
      "35/35 [==============================] - 2s 66ms/step - loss: 1.0695 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.4173 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5937 - prc: 0.3907 - val_loss: 0.9698 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4826 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7174 - val_prc: 0.4939\n",
      "Epoch 16/1000\n",
      "35/35 [==============================] - 2s 64ms/step - loss: 1.0618 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.4139 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6016 - prc: 0.4007 - val_loss: 0.9503 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4925 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7176 - val_prc: 0.4973\n",
      "Epoch 17/1000\n",
      "35/35 [==============================] - 2s 64ms/step - loss: 1.0756 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.4159 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5808 - prc: 0.3791 - val_loss: 0.9803 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7058 - val_prc: 0.4665\n",
      "Epoch 18/1000\n",
      "35/35 [==============================] - 2s 66ms/step - loss: 1.0663 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.4135 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5955 - prc: 0.3949 - val_loss: 0.9746 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7069 - val_prc: 0.4731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000\n",
      "35/35 [==============================] - 2s 66ms/step - loss: 1.0670 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.4058 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5886 - prc: 0.3872 - val_loss: 0.9714 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7123 - val_prc: 0.4866\n",
      "Epoch 20/1000\n",
      "35/35 [==============================] - 2s 64ms/step - loss: 1.0664 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.4082 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5915 - prc: 0.3864 - val_loss: 0.9689 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7102 - val_prc: 0.4766\n",
      "Epoch 21/1000\n",
      "35/35 [==============================] - 2s 63ms/step - loss: 1.0646 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.4159 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5972 - prc: 0.3953 - val_loss: 0.9633 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4378 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7051 - val_prc: 0.4710\n",
      "Epoch 22/1000\n",
      "34/35 [============================>.] - ETA: 0s - loss: 1.0574 - tp: 0.0000e+00 - fp: 2.0000 - tn: 4078.0000 - fn: 2040.0000 - accuracy: 0.4074 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6108 - prc: 0.4004\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "35/35 [==============================] - 2s 63ms/step - loss: 1.0545 - tp: 2.0000 - fp: 3.0000 - tn: 4157.0000 - fn: 2078.0000 - accuracy: 0.4072 - precision: 0.4000 - recall: 9.6154e-04 - auc: 0.6140 - prc: 0.4030 - val_loss: 0.9159 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7044 - val_prc: 0.4616\n",
      "Epoch 23/1000\n",
      "35/35 [==============================] - 2s 66ms/step - loss: 1.0766 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.4101 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5902 - prc: 0.3880 - val_loss: 0.9820 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7159 - val_prc: 0.4859\n",
      "Epoch 24/1000\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 1.0471 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 4160.0000 - fn: 2080.0000 - accuracy: 0.4163 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6269 - prc: 0.4145 - val_loss: 0.9484 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7154 - val_prc: 0.4797\n",
      "Epoch 25/1000\n",
      "35/35 [==============================] - 2s 69ms/step - loss: 1.0278 - tp: 85.0000 - fp: 115.0000 - tn: 4045.0000 - fn: 1995.0000 - accuracy: 0.4096 - precision: 0.4250 - recall: 0.0409 - auc: 0.6410 - prc: 0.4272 - val_loss: 0.9030 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7052 - val_prc: 0.4613\n",
      "Epoch 26/1000\n",
      "35/35 [==============================] - 2s 66ms/step - loss: 1.0179 - tp: 98.0000 - fp: 103.0000 - tn: 4057.0000 - fn: 1982.0000 - accuracy: 0.4207 - precision: 0.4876 - recall: 0.0471 - auc: 0.6490 - prc: 0.4385 - val_loss: 0.9033 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7128 - val_prc: 0.4892\n",
      "Epoch 27/1000\n",
      "35/35 [==============================] - 2s 66ms/step - loss: 0.9937 - tp: 97.0000 - fp: 135.0000 - tn: 4025.0000 - fn: 1983.0000 - accuracy: 0.4216 - precision: 0.4181 - recall: 0.0466 - auc: 0.6635 - prc: 0.4350 - val_loss: 0.9077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7072 - val_prc: 0.4878\n",
      "Epoch 28/1000\n",
      "35/35 [==============================] - 2s 70ms/step - loss: 0.9804 - tp: 260.0000 - fp: 267.0000 - tn: 3893.0000 - fn: 1820.0000 - accuracy: 0.4702 - precision: 0.4934 - recall: 0.1250 - auc: 0.6785 - prc: 0.4562 - val_loss: 0.9037 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7117 - val_prc: 0.4837\n",
      "Epoch 29/1000\n",
      "35/35 [==============================] - 2s 63ms/step - loss: 0.9830 - tp: 108.0000 - fp: 142.0000 - tn: 4018.0000 - fn: 1972.0000 - accuracy: 0.4529 - precision: 0.4320 - recall: 0.0519 - auc: 0.6742 - prc: 0.4429 - val_loss: 0.9114 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7052 - val_prc: 0.4742\n",
      "Epoch 30/1000\n",
      "35/35 [==============================] - 2s 62ms/step - loss: 0.9807 - tp: 170.0000 - fp: 186.0000 - tn: 3974.0000 - fn: 1910.0000 - accuracy: 0.4663 - precision: 0.4775 - recall: 0.0817 - auc: 0.6805 - prc: 0.4545 - val_loss: 0.9055 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7084 - val_prc: 0.4813\n",
      "Epoch 31/1000\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.9803 - tp: 85.0000 - fp: 99.0000 - tn: 4061.0000 - fn: 1995.0000 - accuracy: 0.4692 - precision: 0.4620 - recall: 0.0409 - auc: 0.6795 - prc: 0.4548 - val_loss: 0.9102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7045 - val_prc: 0.4690\n",
      "Epoch 32/1000\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.9820 - tp: 156.0000 - fp: 187.0000 - tn: 3893.0000 - fn: 1884.0000 - accuracy: 0.4578 - precision: 0.4548 - recall: 0.0765 - auc: 0.6760 - prc: 0.4476\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "35/35 [==============================] - 2s 64ms/step - loss: 0.9801 - tp: 156.0000 - fp: 193.0000 - tn: 3967.0000 - fn: 1924.0000 - accuracy: 0.4582 - precision: 0.4470 - recall: 0.0750 - auc: 0.6768 - prc: 0.4472 - val_loss: 0.9037 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7068 - val_prc: 0.4649\n",
      "Epoch 33/1000\n",
      "35/35 [==============================] - 2s 65ms/step - loss: 0.9788 - tp: 71.0000 - fp: 98.0000 - tn: 4062.0000 - fn: 2009.0000 - accuracy: 0.4611 - precision: 0.4201 - recall: 0.0341 - auc: 0.6782 - prc: 0.4482 - val_loss: 0.9057 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7036 - val_prc: 0.4769\n",
      "Epoch 34/1000\n",
      "35/35 [==============================] - 2s 62ms/step - loss: 0.9781 - tp: 144.0000 - fp: 150.0000 - tn: 4010.0000 - fn: 1936.0000 - accuracy: 0.4601 - precision: 0.4898 - recall: 0.0692 - auc: 0.6805 - prc: 0.4605 - val_loss: 0.9041 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7030 - val_prc: 0.4718\n",
      "Epoch 35/1000\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.9777 - tp: 142.0000 - fp: 152.0000 - tn: 4008.0000 - fn: 1938.0000 - accuracy: 0.4635 - precision: 0.4830 - recall: 0.0683 - auc: 0.6805 - prc: 0.4544 - val_loss: 0.9036 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7039 - val_prc: 0.4700\n",
      "Epoch 36/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 64ms/step - loss: 0.9778 - tp: 149.0000 - fp: 168.0000 - tn: 3992.0000 - fn: 1931.0000 - accuracy: 0.4587 - precision: 0.4700 - recall: 0.0716 - auc: 0.6818 - prc: 0.4531 - val_loss: 0.9041 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7035 - val_prc: 0.4658\n",
      "Epoch 37/1000\n",
      "35/35 [==============================] - 2s 64ms/step - loss: 0.9751 - tp: 165.0000 - fp: 175.0000 - tn: 3985.0000 - fn: 1915.0000 - accuracy: 0.4678 - precision: 0.4853 - recall: 0.0793 - auc: 0.6869 - prc: 0.4598 - val_loss: 0.9034 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7028 - val_prc: 0.4646\n",
      "Epoch 38/1000\n",
      "35/35 [==============================] - 2s 62ms/step - loss: 0.9737 - tp: 167.0000 - fp: 170.0000 - tn: 3990.0000 - fn: 1913.0000 - accuracy: 0.4692 - precision: 0.4955 - recall: 0.0803 - auc: 0.6887 - prc: 0.4639 - val_loss: 0.9032 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7057 - val_prc: 0.4719\n",
      "Epoch 39/1000\n",
      "35/35 [==============================] - 2s 63ms/step - loss: 0.9762 - tp: 180.0000 - fp: 176.0000 - tn: 3984.0000 - fn: 1900.0000 - accuracy: 0.4668 - precision: 0.5056 - recall: 0.0865 - auc: 0.6848 - prc: 0.4622 - val_loss: 0.9019 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7071 - val_prc: 0.4700\n",
      "Epoch 40/1000\n",
      "35/35 [==============================] - 2s 61ms/step - loss: 0.9785 - tp: 183.0000 - fp: 181.0000 - tn: 3979.0000 - fn: 1897.0000 - accuracy: 0.4630 - precision: 0.5027 - recall: 0.0880 - auc: 0.6818 - prc: 0.4571 - val_loss: 0.9027 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4627 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7054 - val_prc: 0.4670\n",
      "Epoch 41/1000\n",
      "35/35 [==============================] - 2s 66ms/step - loss: 0.9738 - tp: 194.0000 - fp: 190.0000 - tn: 3970.0000 - fn: 1886.0000 - accuracy: 0.4649 - precision: 0.5052 - recall: 0.0933 - auc: 0.6865 - prc: 0.4643 - val_loss: 0.9015 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4677 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7061 - val_prc: 0.4687\n",
      "Epoch 42/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.9768 - tp: 159.0000 - fp: 166.0000 - tn: 3994.0000 - fn: 1921.0000 - accuracy: 0.4755 - precision: 0.4892 - recall: 0.0764 - auc: 0.6820 - prc: 0.4557\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "35/35 [==============================] - 2s 63ms/step - loss: 0.9768 - tp: 159.0000 - fp: 166.0000 - tn: 3994.0000 - fn: 1921.0000 - accuracy: 0.4755 - precision: 0.4892 - recall: 0.0764 - auc: 0.6820 - prc: 0.4557 - val_loss: 0.9012 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7096 - val_prc: 0.4746\n",
      "Epoch 43/1000\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.9741 - tp: 152.0000 - fp: 158.0000 - tn: 4002.0000 - fn: 1928.0000 - accuracy: 0.4769 - precision: 0.4903 - recall: 0.0731 - auc: 0.6859 - prc: 0.4625 - val_loss: 0.9007 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4527 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7074 - val_prc: 0.4745\n",
      "Epoch 44/1000\n",
      "35/35 [==============================] - 2s 62ms/step - loss: 0.9680 - tp: 202.0000 - fp: 163.0000 - tn: 3997.0000 - fn: 1878.0000 - accuracy: 0.4894 - precision: 0.5534 - recall: 0.0971 - auc: 0.6996 - prc: 0.4884 - val_loss: 0.8998 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 402.0000 - val_fn: 201.0000 - val_accuracy: 0.4428 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7050 - val_prc: 0.4686\n",
      "Epoch 45/1000\n",
      "35/35 [==============================] - 2s 66ms/step - loss: 0.9728 - tp: 200.0000 - fp: 200.0000 - tn: 3960.0000 - fn: 1880.0000 - accuracy: 0.4760 - precision: 0.5000 - recall: 0.0962 - auc: 0.6879 - prc: 0.4730 - val_loss: 0.8999 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 398.0000 - val_fn: 197.0000 - val_accuracy: 0.4677 - val_precision: 0.5000 - val_recall: 0.0199 - val_auc: 0.7056 - val_prc: 0.4705\n",
      "Epoch 46/1000\n",
      "35/35 [==============================] - 2s 63ms/step - loss: 0.9710 - tp: 212.0000 - fp: 183.0000 - tn: 3977.0000 - fn: 1868.0000 - accuracy: 0.4793 - precision: 0.5367 - recall: 0.1019 - auc: 0.6915 - prc: 0.4763 - val_loss: 0.8994 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 398.0000 - val_fn: 197.0000 - val_accuracy: 0.4428 - val_precision: 0.5000 - val_recall: 0.0199 - val_auc: 0.7075 - val_prc: 0.4738\n",
      "Epoch 47/1000\n",
      "35/35 [==============================] - 2s 61ms/step - loss: 0.9721 - tp: 211.0000 - fp: 204.0000 - tn: 3956.0000 - fn: 1869.0000 - accuracy: 0.4827 - precision: 0.5084 - recall: 0.1014 - auc: 0.6901 - prc: 0.4691 - val_loss: 0.8993 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 398.0000 - val_fn: 197.0000 - val_accuracy: 0.4378 - val_precision: 0.5000 - val_recall: 0.0199 - val_auc: 0.7038 - val_prc: 0.4700\n",
      "Epoch 48/1000\n",
      "35/35 [==============================] - 2s 62ms/step - loss: 0.9710 - tp: 218.0000 - fp: 193.0000 - tn: 3967.0000 - fn: 1862.0000 - accuracy: 0.4856 - precision: 0.5304 - recall: 0.1048 - auc: 0.6948 - prc: 0.4816 - val_loss: 0.8994 - val_tp: 5.0000 - val_fp: 5.0000 - val_tn: 397.0000 - val_fn: 196.0000 - val_accuracy: 0.4478 - val_precision: 0.5000 - val_recall: 0.0249 - val_auc: 0.7080 - val_prc: 0.4782\n",
      "Epoch 49/1000\n",
      "35/35 [==============================] - 2s 64ms/step - loss: 0.9702 - tp: 275.0000 - fp: 244.0000 - tn: 3916.0000 - fn: 1805.0000 - accuracy: 0.4663 - precision: 0.5299 - recall: 0.1322 - auc: 0.6938 - prc: 0.4820 - val_loss: 0.8990 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 398.0000 - val_fn: 197.0000 - val_accuracy: 0.4726 - val_precision: 0.5000 - val_recall: 0.0199 - val_auc: 0.7121 - val_prc: 0.4780\n",
      "Epoch 50/1000\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.9752 - tp: 226.0000 - fp: 207.0000 - tn: 3953.0000 - fn: 1854.0000 - accuracy: 0.4529 - precision: 0.5219 - recall: 0.1087 - auc: 0.6793 - prc: 0.4634 - val_loss: 0.8997 - val_tp: 5.0000 - val_fp: 5.0000 - val_tn: 397.0000 - val_fn: 196.0000 - val_accuracy: 0.4328 - val_precision: 0.5000 - val_recall: 0.0249 - val_auc: 0.7076 - val_prc: 0.4752\n",
      "Epoch 51/1000\n",
      "35/35 [==============================] - 2s 67ms/step - loss: 0.9726 - tp: 249.0000 - fp: 225.0000 - tn: 3935.0000 - fn: 1831.0000 - accuracy: 0.4750 - precision: 0.5253 - recall: 0.1197 - auc: 0.6905 - prc: 0.4752 - val_loss: 0.9003 - val_tp: 6.0000 - val_fp: 8.0000 - val_tn: 394.0000 - val_fn: 195.0000 - val_accuracy: 0.4726 - val_precision: 0.4286 - val_recall: 0.0299 - val_auc: 0.7052 - val_prc: 0.4775\n",
      "Epoch 52/1000\n",
      "35/35 [==============================] - 2s 69ms/step - loss: 0.9703 - tp: 255.0000 - fp: 213.0000 - tn: 3947.0000 - fn: 1825.0000 - accuracy: 0.4712 - precision: 0.5449 - recall: 0.1226 - auc: 0.6917 - prc: 0.4782 - val_loss: 0.9002 - val_tp: 6.0000 - val_fp: 7.0000 - val_tn: 395.0000 - val_fn: 195.0000 - val_accuracy: 0.4378 - val_precision: 0.4615 - val_recall: 0.0299 - val_auc: 0.7070 - val_prc: 0.4776\n",
      "Epoch 53/1000\n",
      "35/35 [==============================] - 2s 67ms/step - loss: 0.9717 - tp: 223.0000 - fp: 210.0000 - tn: 3950.0000 - fn: 1857.0000 - accuracy: 0.4832 - precision: 0.5150 - recall: 0.1072 - auc: 0.6921 - prc: 0.4739 - val_loss: 0.8999 - val_tp: 5.0000 - val_fp: 4.0000 - val_tn: 398.0000 - val_fn: 196.0000 - val_accuracy: 0.4677 - val_precision: 0.5556 - val_recall: 0.0249 - val_auc: 0.7093 - val_prc: 0.4784\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 70ms/step - loss: 0.9695 - tp: 253.0000 - fp: 239.0000 - tn: 3921.0000 - fn: 1827.0000 - accuracy: 0.4760 - precision: 0.5142 - recall: 0.1216 - auc: 0.6938 - prc: 0.4768 - val_loss: 0.9003 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 393.0000 - val_fn: 193.0000 - val_accuracy: 0.4677 - val_precision: 0.4706 - val_recall: 0.0398 - val_auc: 0.7065 - val_prc: 0.4763\n",
      "Epoch 55/1000\n",
      "35/35 [==============================] - 2s 64ms/step - loss: 0.9691 - tp: 254.0000 - fp: 221.0000 - tn: 3939.0000 - fn: 1826.0000 - accuracy: 0.4716 - precision: 0.5347 - recall: 0.1221 - auc: 0.6957 - prc: 0.4828 - val_loss: 0.9004 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 393.0000 - val_fn: 194.0000 - val_accuracy: 0.4428 - val_precision: 0.4375 - val_recall: 0.0348 - val_auc: 0.7063 - val_prc: 0.4727\n",
      "Epoch 56/1000\n",
      "35/35 [==============================] - 2s 64ms/step - loss: 0.9703 - tp: 268.0000 - fp: 255.0000 - tn: 3905.0000 - fn: 1812.0000 - accuracy: 0.4663 - precision: 0.5124 - recall: 0.1288 - auc: 0.6883 - prc: 0.4700 - val_loss: 0.9003 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 393.0000 - val_fn: 193.0000 - val_accuracy: 0.4279 - val_precision: 0.4706 - val_recall: 0.0398 - val_auc: 0.7083 - val_prc: 0.4752\n",
      "Epoch 57/1000\n",
      "35/35 [==============================] - 2s 69ms/step - loss: 0.9690 - tp: 246.0000 - fp: 231.0000 - tn: 3929.0000 - fn: 1834.0000 - accuracy: 0.4779 - precision: 0.5157 - recall: 0.1183 - auc: 0.6943 - prc: 0.4783 - val_loss: 0.9005 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 393.0000 - val_fn: 192.0000 - val_accuracy: 0.4328 - val_precision: 0.5000 - val_recall: 0.0448 - val_auc: 0.7102 - val_prc: 0.4769\n",
      "Epoch 58/1000\n",
      "35/35 [==============================] - 3s 76ms/step - loss: 0.9685 - tp: 260.0000 - fp: 255.0000 - tn: 3905.0000 - fn: 1820.0000 - accuracy: 0.4870 - precision: 0.5049 - recall: 0.1250 - auc: 0.6975 - prc: 0.4848 - val_loss: 0.9008 - val_tp: 11.0000 - val_fp: 11.0000 - val_tn: 391.0000 - val_fn: 190.0000 - val_accuracy: 0.4478 - val_precision: 0.5000 - val_recall: 0.0547 - val_auc: 0.7075 - val_prc: 0.4747\n",
      "Epoch 59/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.9694 - tp: 251.0000 - fp: 240.0000 - tn: 3920.0000 - fn: 1829.0000 - accuracy: 0.4832 - precision: 0.5112 - recall: 0.1207 - auc: 0.6965 - prc: 0.4792\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "35/35 [==============================] - 2s 70ms/step - loss: 0.9694 - tp: 251.0000 - fp: 240.0000 - tn: 3920.0000 - fn: 1829.0000 - accuracy: 0.4832 - precision: 0.5112 - recall: 0.1207 - auc: 0.6965 - prc: 0.4792 - val_loss: 0.9013 - val_tp: 10.0000 - val_fp: 11.0000 - val_tn: 391.0000 - val_fn: 191.0000 - val_accuracy: 0.4428 - val_precision: 0.4762 - val_recall: 0.0498 - val_auc: 0.7064 - val_prc: 0.4714\n",
      "Epoch 60/1000\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.9700 - tp: 281.0000 - fp: 268.0000 - tn: 3892.0000 - fn: 1799.0000 - accuracy: 0.4707 - precision: 0.5118 - recall: 0.1351 - auc: 0.6927 - prc: 0.4780 - val_loss: 0.9011 - val_tp: 11.0000 - val_fp: 11.0000 - val_tn: 391.0000 - val_fn: 190.0000 - val_accuracy: 0.4627 - val_precision: 0.5000 - val_recall: 0.0547 - val_auc: 0.7067 - val_prc: 0.4738\n",
      "Epoch 61/1000\n",
      "35/35 [==============================] - 2s 67ms/step - loss: 0.9681 - tp: 258.0000 - fp: 226.0000 - tn: 3934.0000 - fn: 1822.0000 - accuracy: 0.4793 - precision: 0.5331 - recall: 0.1240 - auc: 0.6963 - prc: 0.4829 - val_loss: 0.9014 - val_tp: 10.0000 - val_fp: 11.0000 - val_tn: 391.0000 - val_fn: 191.0000 - val_accuracy: 0.4627 - val_precision: 0.4762 - val_recall: 0.0498 - val_auc: 0.7063 - val_prc: 0.4722\n",
      "Epoch 62/1000\n",
      "35/35 [==============================] - 2s 70ms/step - loss: 0.9695 - tp: 275.0000 - fp: 259.0000 - tn: 3901.0000 - fn: 1805.0000 - accuracy: 0.4803 - precision: 0.5150 - recall: 0.1322 - auc: 0.6938 - prc: 0.4801 - val_loss: 0.9016 - val_tp: 12.0000 - val_fp: 13.0000 - val_tn: 389.0000 - val_fn: 189.0000 - val_accuracy: 0.4577 - val_precision: 0.4800 - val_recall: 0.0597 - val_auc: 0.7077 - val_prc: 0.4730\n",
      "Epoch 63/1000\n",
      "35/35 [==============================] - 2s 67ms/step - loss: 0.9673 - tp: 260.0000 - fp: 244.0000 - tn: 3916.0000 - fn: 1820.0000 - accuracy: 0.4712 - precision: 0.5159 - recall: 0.1250 - auc: 0.6954 - prc: 0.4839 - val_loss: 0.9016 - val_tp: 12.0000 - val_fp: 12.0000 - val_tn: 390.0000 - val_fn: 189.0000 - val_accuracy: 0.4627 - val_precision: 0.5000 - val_recall: 0.0597 - val_auc: 0.7059 - val_prc: 0.4695\n",
      "Epoch 64/1000\n",
      "35/35 [==============================] - 2s 69ms/step - loss: 0.9676 - tp: 294.0000 - fp: 265.0000 - tn: 3895.0000 - fn: 1786.0000 - accuracy: 0.4784 - precision: 0.5259 - recall: 0.1413 - auc: 0.6968 - prc: 0.4881 - val_loss: 0.9016 - val_tp: 10.0000 - val_fp: 11.0000 - val_tn: 391.0000 - val_fn: 191.0000 - val_accuracy: 0.4577 - val_precision: 0.4762 - val_recall: 0.0498 - val_auc: 0.7075 - val_prc: 0.4733\n",
      "Epoch 65/1000\n",
      "35/35 [==============================] - 2s 69ms/step - loss: 0.9657 - tp: 284.0000 - fp: 256.0000 - tn: 3904.0000 - fn: 1796.0000 - accuracy: 0.4923 - precision: 0.5259 - recall: 0.1365 - auc: 0.7005 - prc: 0.4933 - val_loss: 0.9021 - val_tp: 10.0000 - val_fp: 12.0000 - val_tn: 390.0000 - val_fn: 191.0000 - val_accuracy: 0.4627 - val_precision: 0.4545 - val_recall: 0.0498 - val_auc: 0.7075 - val_prc: 0.4720\n",
      "Epoch 66/1000\n",
      "35/35 [==============================] - 3s 75ms/step - loss: 0.9666 - tp: 309.0000 - fp: 251.0000 - tn: 3909.0000 - fn: 1771.0000 - accuracy: 0.4731 - precision: 0.5518 - recall: 0.1486 - auc: 0.6978 - prc: 0.4855 - val_loss: 0.9017 - val_tp: 11.0000 - val_fp: 12.0000 - val_tn: 390.0000 - val_fn: 190.0000 - val_accuracy: 0.4428 - val_precision: 0.4783 - val_recall: 0.0547 - val_auc: 0.7080 - val_prc: 0.4740\n",
      "Epoch 67/1000\n",
      "35/35 [==============================] - 2s 66ms/step - loss: 0.9669 - tp: 279.0000 - fp: 246.0000 - tn: 3914.0000 - fn: 1801.0000 - accuracy: 0.4707 - precision: 0.5314 - recall: 0.1341 - auc: 0.6946 - prc: 0.4806 - val_loss: 0.9020 - val_tp: 12.0000 - val_fp: 12.0000 - val_tn: 390.0000 - val_fn: 189.0000 - val_accuracy: 0.4577 - val_precision: 0.5000 - val_recall: 0.0597 - val_auc: 0.7086 - val_prc: 0.4721\n",
      "Epoch 68/1000\n",
      "35/35 [==============================] - 2s 65ms/step - loss: 0.9674 - tp: 294.0000 - fp: 273.0000 - tn: 3887.0000 - fn: 1786.0000 - accuracy: 0.4731 - precision: 0.5185 - recall: 0.1413 - auc: 0.6953 - prc: 0.4809 - val_loss: 0.9022 - val_tp: 12.0000 - val_fp: 12.0000 - val_tn: 390.0000 - val_fn: 189.0000 - val_accuracy: 0.4577 - val_precision: 0.5000 - val_recall: 0.0597 - val_auc: 0.7083 - val_prc: 0.4787\n",
      "Epoch 69/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.9692 - tp: 306.0000 - fp: 280.0000 - tn: 3880.0000 - fn: 1774.0000 - accuracy: 0.4808 - precision: 0.5222 - recall: 0.1471 - auc: 0.6938 - prc: 0.4814ETA: 0s - loss: 1.0049 - tp: 219.0000 - fp: 201.0000 - tn: 2199.0000 - fn: 981.0000 - accuracy: 0.4833 - precision: 0.5214 - recall: 0.1825 - auc: 0.67\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "35/35 [==============================] - 2s 66ms/step - loss: 0.9692 - tp: 306.0000 - fp: 280.0000 - tn: 3880.0000 - fn: 1774.0000 - accuracy: 0.4808 - precision: 0.5222 - recall: 0.1471 - auc: 0.6938 - prc: 0.4814 - val_loss: 0.9023 - val_tp: 12.0000 - val_fp: 12.0000 - val_tn: 390.0000 - val_fn: 189.0000 - val_accuracy: 0.4577 - val_precision: 0.5000 - val_recall: 0.0597 - val_auc: 0.7099 - val_prc: 0.4737\n",
      "Epoch 70/1000\n",
      "35/35 [==============================] - 3s 73ms/step - loss: 0.9676 - tp: 280.0000 - fp: 228.0000 - tn: 3932.0000 - fn: 1800.0000 - accuracy: 0.4817 - precision: 0.5512 - recall: 0.1346 - auc: 0.6982 - prc: 0.4905 - val_loss: 0.9024 - val_tp: 11.0000 - val_fp: 12.0000 - val_tn: 390.0000 - val_fn: 190.0000 - val_accuracy: 0.4527 - val_precision: 0.4783 - val_recall: 0.0547 - val_auc: 0.7089 - val_prc: 0.4720\n",
      "Epoch 71/1000\n",
      "35/35 [==============================] - 2s 67ms/step - loss: 0.9689 - tp: 279.0000 - fp: 252.0000 - tn: 3908.0000 - fn: 1801.0000 - accuracy: 0.4755 - precision: 0.5254 - recall: 0.1341 - auc: 0.6929 - prc: 0.4794 - val_loss: 0.9025 - val_tp: 12.0000 - val_fp: 12.0000 - val_tn: 390.0000 - val_fn: 189.0000 - val_accuracy: 0.4577 - val_precision: 0.5000 - val_recall: 0.0597 - val_auc: 0.7099 - val_prc: 0.4812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "35/35 [==============================] - 2s 66ms/step - loss: 0.9671 - tp: 287.0000 - fp: 264.0000 - tn: 3896.0000 - fn: 1793.0000 - accuracy: 0.4769 - precision: 0.5209 - recall: 0.1380 - auc: 0.6967 - prc: 0.4856 - val_loss: 0.9025 - val_tp: 12.0000 - val_fp: 12.0000 - val_tn: 390.0000 - val_fn: 189.0000 - val_accuracy: 0.4478 - val_precision: 0.5000 - val_recall: 0.0597 - val_auc: 0.7085 - val_prc: 0.4744\n",
      "Epoch 73/1000\n",
      "35/35 [==============================] - 2s 65ms/step - loss: 0.9663 - tp: 312.0000 - fp: 260.0000 - tn: 3900.0000 - fn: 1768.0000 - accuracy: 0.4774 - precision: 0.5455 - recall: 0.1500 - auc: 0.6982 - prc: 0.4878 - val_loss: 0.9026 - val_tp: 12.0000 - val_fp: 12.0000 - val_tn: 390.0000 - val_fn: 189.0000 - val_accuracy: 0.4627 - val_precision: 0.5000 - val_recall: 0.0597 - val_auc: 0.7066 - val_prc: 0.4763\n",
      "Epoch 74/1000\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.9659 - tp: 316.0000 - fp: 270.0000 - tn: 3890.0000 - fn: 1764.0000 - accuracy: 0.4880 - precision: 0.5392 - recall: 0.1519 - auc: 0.6988 - prc: 0.4932 - val_loss: 0.9025 - val_tp: 13.0000 - val_fp: 13.0000 - val_tn: 389.0000 - val_fn: 188.0000 - val_accuracy: 0.4627 - val_precision: 0.5000 - val_recall: 0.0647 - val_auc: 0.7061 - val_prc: 0.4736\n",
      "Epoch 75/1000\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.9642 - tp: 319.0000 - fp: 270.0000 - tn: 3890.0000 - fn: 1761.0000 - accuracy: 0.4837 - precision: 0.5416 - recall: 0.1534 - auc: 0.7012 - prc: 0.4922 - val_loss: 0.9025 - val_tp: 13.0000 - val_fp: 13.0000 - val_tn: 389.0000 - val_fn: 188.0000 - val_accuracy: 0.4627 - val_precision: 0.5000 - val_recall: 0.0647 - val_auc: 0.7060 - val_prc: 0.4714\n",
      "Epoch 76/1000\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.9682 - tp: 318.0000 - fp: 283.0000 - tn: 3877.0000 - fn: 1762.0000 - accuracy: 0.4712 - precision: 0.5291 - recall: 0.1529 - auc: 0.6967 - prc: 0.4862 - val_loss: 0.9024 - val_tp: 13.0000 - val_fp: 13.0000 - val_tn: 389.0000 - val_fn: 188.0000 - val_accuracy: 0.4527 - val_precision: 0.5000 - val_recall: 0.0647 - val_auc: 0.7083 - val_prc: 0.4753\n",
      "Epoch 77/1000\n",
      "35/35 [==============================] - 3s 77ms/step - loss: 0.9673 - tp: 326.0000 - fp: 280.0000 - tn: 3880.0000 - fn: 1754.0000 - accuracy: 0.4755 - precision: 0.5380 - recall: 0.1567 - auc: 0.6983 - prc: 0.4869 - val_loss: 0.9026 - val_tp: 13.0000 - val_fp: 13.0000 - val_tn: 389.0000 - val_fn: 188.0000 - val_accuracy: 0.4527 - val_precision: 0.5000 - val_recall: 0.0647 - val_auc: 0.7094 - val_prc: 0.4764\n",
      "Epoch 78/1000\n",
      "35/35 [==============================] - 3s 78ms/step - loss: 0.9658 - tp: 320.0000 - fp: 282.0000 - tn: 3878.0000 - fn: 1760.0000 - accuracy: 0.4851 - precision: 0.5316 - recall: 0.1538 - auc: 0.7006 - prc: 0.4906 - val_loss: 0.9026 - val_tp: 14.0000 - val_fp: 13.0000 - val_tn: 389.0000 - val_fn: 187.0000 - val_accuracy: 0.4577 - val_precision: 0.5185 - val_recall: 0.0697 - val_auc: 0.7083 - val_prc: 0.4734\n",
      "Epoch 79/1000\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.9685 - tp: 306.0000 - fp: 266.0000 - tn: 3814.0000 - fn: 1734.0000 - accuracy: 0.4760 - precision: 0.5350 - recall: 0.1500 - auc: 0.6956 - prc: 0.4824\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "35/35 [==============================] - 2s 68ms/step - loss: 0.9661 - tp: 311.0000 - fp: 268.0000 - tn: 3892.0000 - fn: 1769.0000 - accuracy: 0.4779 - precision: 0.5371 - recall: 0.1495 - auc: 0.6974 - prc: 0.4840 - val_loss: 0.9030 - val_tp: 14.0000 - val_fp: 13.0000 - val_tn: 389.0000 - val_fn: 187.0000 - val_accuracy: 0.4627 - val_precision: 0.5185 - val_recall: 0.0697 - val_auc: 0.7062 - val_prc: 0.4704\n",
      "Epoch 80/1000\n",
      "35/35 [==============================] - 2s 69ms/step - loss: 0.9644 - tp: 327.0000 - fp: 288.0000 - tn: 3872.0000 - fn: 1753.0000 - accuracy: 0.4812 - precision: 0.5317 - recall: 0.1572 - auc: 0.7007 - prc: 0.4898 - val_loss: 0.9030 - val_tp: 14.0000 - val_fp: 13.0000 - val_tn: 389.0000 - val_fn: 187.0000 - val_accuracy: 0.4627 - val_precision: 0.5185 - val_recall: 0.0697 - val_auc: 0.7073 - val_prc: 0.4726\n",
      "Epoch 81/1000\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.9670 - tp: 307.0000 - fp: 282.0000 - tn: 3878.0000 - fn: 1773.0000 - accuracy: 0.4736 - precision: 0.5212 - recall: 0.1476 - auc: 0.6951 - prc: 0.4803 - val_loss: 0.9030 - val_tp: 14.0000 - val_fp: 13.0000 - val_tn: 389.0000 - val_fn: 187.0000 - val_accuracy: 0.4627 - val_precision: 0.5185 - val_recall: 0.0697 - val_auc: 0.7065 - val_prc: 0.4708\n",
      "Epoch 82/1000\n",
      "35/35 [==============================] - 2s 67ms/step - loss: 0.9659 - tp: 325.0000 - fp: 286.0000 - tn: 3874.0000 - fn: 1755.0000 - accuracy: 0.4856 - precision: 0.5319 - recall: 0.1562 - auc: 0.6992 - prc: 0.4890 - val_loss: 0.9030 - val_tp: 14.0000 - val_fp: 13.0000 - val_tn: 389.0000 - val_fn: 187.0000 - val_accuracy: 0.4627 - val_precision: 0.5185 - val_recall: 0.0697 - val_auc: 0.7068 - val_prc: 0.4716\n",
      "Epoch 83/1000\n",
      "35/35 [==============================] - 2s 66ms/step - loss: 0.9684 - tp: 296.0000 - fp: 263.0000 - tn: 3897.0000 - fn: 1784.0000 - accuracy: 0.4750 - precision: 0.5295 - recall: 0.1423 - auc: 0.6942 - prc: 0.4802 - val_loss: 0.9032 - val_tp: 14.0000 - val_fp: 13.0000 - val_tn: 389.0000 - val_fn: 187.0000 - val_accuracy: 0.4677 - val_precision: 0.5185 - val_recall: 0.0697 - val_auc: 0.7088 - val_prc: 0.4733\n",
      "Epoch 84/1000\n",
      "35/35 [==============================] - 3s 73ms/step - loss: 0.9657 - tp: 307.0000 - fp: 265.0000 - tn: 3895.0000 - fn: 1773.0000 - accuracy: 0.4798 - precision: 0.5367 - recall: 0.1476 - auc: 0.6983 - prc: 0.4865 - val_loss: 0.9033 - val_tp: 14.0000 - val_fp: 13.0000 - val_tn: 389.0000 - val_fn: 187.0000 - val_accuracy: 0.4677 - val_precision: 0.5185 - val_recall: 0.0697 - val_auc: 0.7084 - val_prc: 0.4723\n",
      "Epoch 85/1000\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.9666 - tp: 292.0000 - fp: 283.0000 - tn: 3877.0000 - fn: 1788.0000 - accuracy: 0.4861 - precision: 0.5078 - recall: 0.1404 - auc: 0.6987 - prc: 0.4836 - val_loss: 0.9033 - val_tp: 14.0000 - val_fp: 13.0000 - val_tn: 389.0000 - val_fn: 187.0000 - val_accuracy: 0.4677 - val_precision: 0.5185 - val_recall: 0.0697 - val_auc: 0.7081 - val_prc: 0.4716\n",
      "Epoch 86/1000\n",
      "35/35 [==============================] - 2s 70ms/step - loss: 0.9641 - tp: 322.0000 - fp: 287.0000 - tn: 3873.0000 - fn: 1758.0000 - accuracy: 0.4913 - precision: 0.5287 - recall: 0.1548 - auc: 0.7030 - prc: 0.4945 - val_loss: 0.9033 - val_tp: 14.0000 - val_fp: 13.0000 - val_tn: 389.0000 - val_fn: 187.0000 - val_accuracy: 0.4677 - val_precision: 0.5185 - val_recall: 0.0697 - val_auc: 0.7079 - val_prc: 0.4714\n",
      "Epoch 87/1000\n",
      "35/35 [==============================] - 2s 64ms/step - loss: 0.9671 - tp: 324.0000 - fp: 269.0000 - tn: 3891.0000 - fn: 1756.0000 - accuracy: 0.4760 - precision: 0.5464 - recall: 0.1558 - auc: 0.6979 - prc: 0.4845 - val_loss: 0.9033 - val_tp: 14.0000 - val_fp: 13.0000 - val_tn: 389.0000 - val_fn: 187.0000 - val_accuracy: 0.4677 - val_precision: 0.5185 - val_recall: 0.0697 - val_auc: 0.7072 - val_prc: 0.4702\n",
      "Epoch 88/1000\n",
      "12/35 [=========>....................] - ETA: 1s - loss: 1.0202 - tp: 179.0000 - fp: 128.0000 - tn: 1312.0000 - fn: 541.0000 - accuracy: 0.4958 - precision: 0.5831 - recall: 0.2486 - auc: 0.6668 - prc: 0.4897"
     ]
    }
   ],
   "source": [
    "model,history= basic_lstm(input_dim, feature_size)\n",
    "model.save('./saveModel/LSTM_3to1.h5')\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history_dict['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-method",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# “bo”代表 \"蓝点\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b代表“蓝色实线”\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # 清除数字\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(2,2,n+1)\n",
    "        plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == 'auc':\n",
    "            plt.ylim([0.8,1])\n",
    "        else:\n",
    "            plt.ylim([0,1])\n",
    "\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-chorus",
   "metadata": {},
   "source": [
    "### Note: That the validation curve generally performs better than the training curve. This is mainly caused by the fact that the dropout layer is not active when evaluating the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-couple",
   "metadata": {},
   "source": [
    "\n",
    "### Evaluate metrics \n",
    "### You can use a confusion matrix to summarize the actual vs. predicted labels where the X axis is the predicted label  and the Y axis is the actual label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_baseline = model.predict(X_train, batch_size=BATCH_SIZE)\n",
    "test_predictions_baseline = model.predict(X_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-yeast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-result",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = model.evaluate(X_test, y_test,\n",
    "                                  batch_size=BATCH_SIZE, verbose=1)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "#plot_cm(y_test, test_predictions_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-window",
   "metadata": {},
   "source": [
    "# 绘制ROC曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import label_binarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "#同时也是分类得分y_score\n",
    "#概率矩阵P和标签矩阵L分别对应代码中的y_score和y_one_hot：\n",
    "yhat = model.predict(X_test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_count = {}\n",
    "dict_count['跌']=0\n",
    "dict_count['涨']=0\n",
    "dict_count['平']=0\n",
    "for i in range(len(y_test)):\n",
    "    if(y_test[i][0] ==1):\n",
    "        dict_count['跌'] += 1\n",
    "    if(y_test[i][1] == 1):\n",
    "        dict_count['平'] += 1\n",
    "    if(y_test[i][2] == 1):\n",
    "        dict_count['涨'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算属于各个类别的概率，返回值的shape = [n_samples, n_classes]\n",
    "y_score = model.predict(X_test)\n",
    "# 1、调用函数计算micro类型的AUC\n",
    "print('调用函数auc：', metrics.roc_auc_score(y_test, y_score, average='micro'))\n",
    "# 2、手动计算micro类型的AUC\n",
    "#首先将矩阵y_one_hot和y_score展开，然后计算假正例率FPR和真正例率TPR\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test.ravel(),y_score.ravel())\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print('手动计算auc：', auc)\n",
    "#绘图\n",
    "mpl.rcParams['font.sans-serif'] = u'SimHei'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "#FPR就是横坐标,TPR就是纵坐标\n",
    "plt.plot(fpr, tpr, c = 'r', lw = 2, alpha = 0.7, label = u'AUC=%.3f' % auc)\n",
    "plt.plot((0, 1), (0, 1), c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.xlabel('False Positive Rate', fontsize=13)\n",
    "plt.ylabel('True Positive Rate', fontsize=13)\n",
    "plt.grid(b=True, ls=':')\n",
    "plt.legend(loc='lower right', fancybox=True, framealpha=0.8, fontsize=12)\n",
    "plt.title(u'mtj_june数据集分类后的ROC和AUC', fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-collect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-ottawa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-condition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-particle",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, average_precision_score,precision_score,f1_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_0_1(y):\n",
    "    res = []\n",
    "    for i in range(y.shape[0]):\n",
    "        if(y[i][0] > y[i][1] and y[i][0] > y[i][2]):\n",
    "            res.append(-1) #跌\n",
    "        if(y[i][1] > y[i][0] and y[i][1] > y[i][2]):\n",
    "            res.append(0) #平\n",
    "        if(y[i][2] > y[i][0] and y[i][2] > y[i][1]):\n",
    "            res.append(1) #涨\n",
    "    return np.array(res)\n",
    "\n",
    "def result_to_0_1(y):\n",
    "        if(tf.is_tensor(y)):\n",
    "            y = y.numpy()\n",
    "            for i in range(y.shape[0]):\n",
    "                max_index = 0\n",
    "                if(y[i][max_index] < y[i][1]):\n",
    "                    max_index = 1\n",
    "                if(y[i][max_index] < y[i][2]):\n",
    "                    max_index = 2\n",
    "                list_temp = [0,1,2]\n",
    "                list_temp.pop(max_index)\n",
    "                y[i][max_index] = 1\n",
    "                y[i][list_temp[0]] = 0\n",
    "                y[i][list_temp[1]] = 0\n",
    "        else:\n",
    "            for i in range(y.shape[0]):\n",
    "                max_index = 0\n",
    "                if(y[i][max_index] < y[i][1]):\n",
    "                    max_index = 1\n",
    "                if(y[i][max_index] < y[i][2]):\n",
    "                    max_index = 2\n",
    "                list_temp = [0,1,2]\n",
    "                list_temp.pop(max_index)\n",
    "                y[i][max_index] = 1\n",
    "                y[i][list_temp[0]] = 0\n",
    "                y[i][list_temp[1]] = 0\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-advertiser",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = result_to_0_1(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = to_0_1(yhat)\n",
    "y_true = to_0_1(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pre)\n",
    "conf_matrix = pd.DataFrame(cm, index=['跌','平','涨'], columns=['跌','平','涨'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot size setting\n",
    "fig, ax = plt.subplots(figsize = (9,6))\n",
    "sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 19},fmt='.20g', cmap=\"Blues\")\n",
    "plt.ylabel('True label', fontsize=18)\n",
    "plt.xlabel('Predicted label', fontsize=18)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.savefig('confusion.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------Weighted------')\n",
    "print('Weighted precision', precision_score(y_true, y_pre, average='weighted'))\n",
    "print('Weighted recall', recall_score(y_true, y_pre, average='weighted'))\n",
    "print('Weighted f1-score', f1_score(y_true, y_pre, average='weighted'))\n",
    "print('------Macro------')\n",
    "print('Macro precision', precision_score(y_true, y_pre, average='macro'))\n",
    "print('Macro recall', recall_score(y_true, y_pre, average='macro'))\n",
    "print('Macro f1-score', f1_score(y_true, y_pre, average='macro'))\n",
    "print('------Micro------')\n",
    "print('Micro precision', precision_score(y_true, y_pre, average='micro'))\n",
    "print('Micro recall', recall_score(y_true, y_pre, average='micro'))\n",
    "print('Micro f1-score', f1_score(y_true, y_pre, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "# 计算每一类的ROC\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = 3\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "# Compute micro-average ROC curve and ROC area（方法二）\n",
    "fpr[\"weighted\"], tpr[\"weighted\"], _ = roc_curve(\n",
    "    y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"weighted\"] = metrics.auc(fpr[\"weighted\"], tpr[\"weighted\"])\n",
    "\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area（方法一）\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = metrics.auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "lw = 2\n",
    "plt.figure()\n",
    "# plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "#          label='micro-average ROC curve (area = {0:0.4f})'\n",
    "#          ''.format(roc_auc[\"micro\"]),\n",
    "#          color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.4f})'\n",
    "         ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "plt.plot(fpr[\"weighted\"], tpr[\"weighted\"],\n",
    "         label='weighted-average ROC curve (area = {0:0.4f})'\n",
    "         ''.format(roc_auc[\"weighted\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "# # 计算每一类的ROC\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "# n_classes=3\n",
    "# for i in range(n_classes):\n",
    "#     fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "#     roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "# # Compute micro-average ROC curve and ROC area（方法二）\n",
    "# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "# # Compute macro-average ROC curve and ROC area（方法一）\n",
    "# # First aggregate all false positive rates\n",
    "# all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "# # Then interpolate all ROC curves at this points\n",
    "# mean_tpr = np.zeros_like(all_fpr)\n",
    "# for i in range(n_classes):\n",
    "#     mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "# # Finally average it and compute AUC\n",
    "# mean_tpr /= n_classes\n",
    "# fpr[\"macro\"] = all_fpr\n",
    "# tpr[\"macro\"] = mean_tpr\n",
    "# roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# # Plot all ROC curves\n",
    "# lw=2\n",
    "# plt.figure()\n",
    "# plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "#          label='micro-average ROC curve (area = {0:0.4f})'\n",
    "#                ''.format(roc_auc[\"micro\"]),\n",
    "#          color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "# plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "#          label='macro-average ROC curve (area = {0:0.4f})'\n",
    "#                ''.format(roc_auc[\"macro\"]),\n",
    "#          color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "# colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "# for i, color in zip(range(n_classes), colors):\n",
    "#     plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "#              label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "#              ''.format(i, roc_auc[i]))\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-valuation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-dialogue",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-cisco",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-grant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-medline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
